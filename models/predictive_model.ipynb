{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Prediction Model\n",
    "In this notebook, we run through an experiment using UserALE data generated within an instantiation of Superset.  This data reflects four simulated user sessions in which the user performs three tasks within the Video Game Sales example dashboard:\n",
    "\n",
    "1. Filter the games for Wii, Racing, and Nintendo.\n",
    "2. Find Mario Kart in the list of games.\n",
    "3. Determine the difference in global sales between the 3DS game Nintendogs + cats and Wii Sports.\n",
    "\n",
    "The data of these four sessions is captured in a json file within the data folder entitled `task_example.json`.  In this experiment, we will:\n",
    "\n",
    "* Experiment with the efficacy of several predictive models to determine which is the best for our objective\n",
    "* Attempt to plug the `DiGraph` objects resulting from `task_example.json` into the model we choose\n",
    "* Tune the resulting model to minimize loss and maximize prediction accuracy\n",
    "\n",
    "**Note: The data utilized in this example was not data collected in any user study.  Rather this data is simulated through developer interactions with the Superset dashboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code:\n",
    "\n",
    "Generates the graph lists and structures that we'll eventually use for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import datetime\n",
    "import distill\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "def setup(file, date_type):\n",
    "    with open(file) as json_file:\n",
    "        raw_data = json.load(json_file)\n",
    "\n",
    "    data = {}\n",
    "    for log in raw_data:\n",
    "        data[distill.getUUID(log)] = log\n",
    "        \n",
    "    # Convert clientTime to specified type\n",
    "    for uid in data:\n",
    "        log = data[uid]\n",
    "        client_time = log['clientTime']\n",
    "        if date_type == \"integer\":\n",
    "            log['clientTime'] = distill.epoch_to_datetime(client_time)\n",
    "        elif date_type == \"datetime\":\n",
    "            log['clientTime'] = pd.to_datetime(client_time, unit='ms', origin='unix')\n",
    "\n",
    "    # Sort\n",
    "    sorted_data = sorted(data.items(), key=lambda kv: kv[1]['clientTime'])\n",
    "    sorted_dict = dict(sorted_data)\n",
    "\n",
    "    return (sorted_data, sorted_dict)\n",
    "\n",
    "def draw_digraph(segments):\n",
    "    nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "    edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "    \n",
    "    # Set coloring of graph based on element in Superset dashboard\n",
    "    color_map = []\n",
    "    for segment in segments:\n",
    "        if re.match(\"Game_Filter\\S*\", segment.segment_name):\n",
    "            color_map.append('green')\n",
    "        else:\n",
    "            color_map.append('blue')\n",
    "    \n",
    "    graph = distill.createDiGraph(nodes, edges)\n",
    "    nx.draw(graph, node_color=color_map)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_many_session = setup(\"./data/task_example.json\", \"datetime\")\n",
    "sorted_dict = data_many_session[1]\n",
    "\n",
    "# Create segments based on sessionID\n",
    "segments = distill.Segments()\n",
    "session_ids = sorted(distill.find_meta_values('sessionID', sorted_dict), key=lambda sessionID: sessionID)\n",
    "for session_id in session_ids:\n",
    "    segments.append_segments(distill.generate_collapsing_window_segments(sorted_dict, 'sessionID', [session_id], session_id))\n",
    "    \n",
    "# Improve readability of Segment names\n",
    "for index in range(len(segments)):\n",
    "    segments[index].segment_name = \"Session\" + str(index)\n",
    "    \n",
    "    \n",
    "segment_names = [segment.segment_name for segment in segments]\n",
    "start_end_vals = [segment.start_end_val for segment in segments]\n",
    "segment_map = distill.write_segment(sorted_dict, segment_names, start_end_vals)\n",
    "\n",
    "session_0_segments = distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_1_segments = distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_2_segments = distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_3_segments = distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "\n",
    "session_0_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_1_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_2_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_3_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "\n",
    "segments.append_segments(session_0_segments)\n",
    "segments.append_segments(session_1_segments)\n",
    "segments.append_segments(session_2_segments)\n",
    "segments.append_segments(session_3_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example user-activity graph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/n0lEQVR4nO3dd1gUV9sG8HtmdpEOCgIiihV7QbB3jQ2Nmhg1Ro3GaOwlieZNbyYmUdPsxp5YE0uKLXaNYgPELjawUGwoAtJ2Z74/9mMTxILsDAvL/bsur8Du8pwHNXjvmTnnCIqiKCAiIiIiyifR2g0QERERUdHGQElEREREFmGgJCIiIiKLMFASERERkUUYKImIiIjIIgyURERERGQRBkoiIiIisggDJRERERFZhIGSiIiIiCzCQElEREREFmGgJCIiIiKLMFASERERkUUYKImIiIjIIgyURERERGQRBkoiIiIisggDJRERERFZhIGSiIiIiCzCQElEREREFmGgJCIiIiKLMFASERERkUUYKImIiIjIIgyURERERGQRBkoiIiIisggDJRERERFZhIGSiIiIiCzCQElEREREFmGgJCIiIiKLMFASERERkUUYKImIiIjIIgyURERERGQRBkoiIiIisggDJRERERFZhIGSiIiIiCzCQElEREREFmGgJCIiIiKLMFASERERkUV01m6Ans5oBFJTAUUBnJwAHf/UiIiIqBDhDGUhFREBTJgANGxoCpFuboC7O+DoCNSvD4wcCezfbwqZRERERNYkKAojSWHyzz/Am28C4eGmmUiD4dGvy36uRg1g2jSga9eC7ZOIiIgoG2coC4n0dGD8eKB1ayAy0vTY48Lkf5+LigK6dQMGDQLu39e8TSIiIqJcOENZCKSmmmYY//kHkOX81ZAkoHZtYOdOwMND3f6IiIiInoSB0spkGejSBdixI/9hMpskme6vPHAAKFFClfaIiIiInoqXvK1s5kxg2zbLwyRgWg0eEQF89pnltYiIiIjyijOUVhQTA1SvDmRkqFtXEEyLegID1a1LRERE9CicobSimTOfvPAmvyQJmD5d/bpEREREj8IZSitJSwN8fLRbma3TAbGxgJeXNvWJiIiIsnGG0kpCQ7Xd5sdgMC30ISIiItIaA6WVhIebLk1rRa83jUFERESkNQZKKzl9Wtv6WVnAyZPajkFEREQEMFBaTWqqOlsFPUlysrb1iYiIiAAGSqvR6wFR4999Oztt6xMREREBDJRWU6mSab9Ireh0QNWq2tUnIiIiysZAaSVBQdrsQZnNaDSNQURERKQ1BkoradZM20veigK0aqVdfSIiIqJsDJRW4uMDdO9uujStNlEEmjQBatVSvzYRERHRwxgorWj8eG0ue8syMGGC+nWJiIiIHoWB0oratAH691d3g3OdDnjuOaBPH/VqEhERET0Jz/K2ssREoGZN4PZt00IaS4gi4OQEnDoFlC+vTn9ERERET8MZSisrVQrYuRNwdbVsplKSgBIlgK1bGSaJiIioYDFQFgK1agGhoUDFivlb+S2KgLe3gl27ZDRrpn5/RERERE/CQFlIVK9uOnt74kRTQMxLsJQk0+boQ4cClSp1RatW9pgxYwYyMzO1b5iIiIjo/zFQFiL29sA33wBXrwIffwz4+T3+td7ewNtvAxcvAvPnA9Wrl0VWVhbGjx+PSpUqYfHixTBouXM6ERER0f/jopxC7tYtICLCtGhHlgEPDyAwEChTJufr1qxZg5dffjnHYxUrVsSUKVNyPU5ERESkJgZKG3Hq1CnUqVPnkc9dvnwZFStWLOCOiIiIqLjgJW8bERAQAOmhZeL29vZYtGgRwyQRERFpioHSRtjZ2ZmDoyAIAIARI0ZgyJAh1myLiIiIigEGShsSGBgIABgzZgwmTZqEmTNn4uDBg1buioiIiGwd76G0IdHR0YiLi0Pz5s2RlZWFVq1aIT4+HpGRkXB3d7d2e0RERGSjGChtWExMDOrVq4dOnTphzZo15kvhRERERGriJW8bVqFCBSxYsAC//fYbFi5caO12iIiIyEZxhrIYGDZsGFasWIGwsDDUrFnT2u0QERGRjWGgLAYePHiA4OBg6HQ6HD58GA4ODtZuiYiIiGwIL3kXA46OjlizZg3Onz+PiRMnWrsdIiIisjEMlMVEnTp18N1332HOnDnYsGGDtdshIiIiG8JL3sWIoijo1asX9uzZg8jISJQvX97aLREREZENYKAsZhITE1GvXj1UqFABu3fvhk6ns3ZLREREVMTxkncxU6pUKaxcuRKhoaGYPHmytdshIiIiG8BAWQy1bNkSH3/8Mb744gvs3bvX2u0QERFREcdL3sWU0WhEu3btcOnSJRw/fhweHh7WbomIiIiKKM5QFlOSJGHFihVIS0vDkCFDwPcVRERElF8MlMWYn58fFi9ejD///BOzZ8+2djtERERURPGSN2Hs2LFYsGABDh8+jHr16lm7HSIiIipiGCgJ6enpaNy4MTIyMhAeHg4nJydrt0RERERFCC95E+zt7bF69Wpcu3YN48ePt3Y7REREVMQwUBIAoEaNGpgxYwYWLVqENWvWWLsdIiIiKkJ4yZvMFEVBv379sGXLFkRGRqJixYrWbomIiIiKAAZKyiEpKQmBgYHw8vLCP//8A71eb+2WiIiIqJDjJW/Kwc3NDatWrUJ4eDg++ugja7dDRERERQADJeXSuHFjfPHFF/jmm2+wfft2a7dDREREhRwvedMjybKMzp074+TJkzh+/Di8vLys3RIREREVUpyhpEcSRRE///wzjEYjBg0aBFmWrd0SERERFVIMlPRYPj4++Pnnn7F161Z8//331m6HiIiICile8qanmjhxImbMmIHQ0FAEBwdbux0iIiIqZBgo6akyMzPRvHlz3L17FxEREXB1dbV2S0RERFSIMFBSnly8eBGBgYHo2bMnfvnlF/PjN28Cf/0FhIUBERHAvXuAKAL+/kBwMNCsGdCxI6DTWa93IiIi0hYDJeXZihUrMGDAACxbtgwNGryKKVOA334DDAZArweysv59rSAAkmR6ztsbGD0aeOstwMnJev0TERGRNhgo6Zm8+urrWL3aH7L8EQRBgMGQt68TRcDPD/j5Z6B1a217JCIiooLFVd6UZ6mpwNWr85GV9RGMxryHSQCQZSA2FmjbFpg3T7seiYiIqOBxhpLyJDMTCAkB9uwBjEbL6y1cCLz+uuV1iIiIyPo4Q0l58uWXwK5d6oRJABgxAjh9Wp1aREREZF2coaSniow0rdhWK0wCplXfdeoAR45wBTgREVFRxxlKeqpPPlG/psEAHDsGbNyofm0iIiIqWJyhpCe6ds20p6QWf0skybTie+dO9WsTERFRweEMJT3R2rWmPSW1YDSa7su8fVub+kRERFQwGCitJDMTuHsXuH/ftKVOYRUWpl2gzBYRoW19IiIi0hYDZQGRZWDrVmDIEKBGDcDBAShVCnBzA5ydgebNgf/9Dzh71tqd5hQWpu5inIdJkuleSiIiIiq6GCg1piim02EqVgS6dAF++QU4dy7nrGRaGhAaCnz3HVCzJtCmDXD8uNVazuHuXW3ri6Lp/G8iIiIquhgoNZSQAHTtCgwaBFy9anrsSafLZD+3fz8QFAR89pm2s4MAkJ6ejsGDB+PLL7/EkSNHYHxoQLEA/oYUxBhERESkHa7y1siVK0CrVkBc3JND5JMIAvDSS8DKldrt1Xjjxg34+PiYP3dxcUGHDh3QoUMHtG3bFi+/XA2RkdqMDZjC5PffA+PGaTcGERERaYuBUgOJiaYZxuvX8x8mswkCMHgwsHixKq09ko+PD27cuPHI5/r2vYf1692QlaXd+Pv3m+4hJSIioqKJZ5RoYNw40/6NalyuVhRgyRLTpfNevSyvB5hmJcPDwxEWFoawsDDce8xNjEOGDEGLFm749Vd1xn0UvR6oX1+7+kRERKQ9zlCqbMsWICRE3ZqCALi7A5cuASVLPtvX3rlzJ0d4DAsLw7Vr1wAApUqVQnBwMNLT07F//37IsgydTgcnJyf8+uuv6NixI+7fB7y9gfR0db8nwHQZ/+WXTQuViIiIqOhioFRZy5bAwYPqL6YRBODbb4E333z8a+7du4eIiIgc4TE6OhoA4OrqiuDg4By/KlSoAEEQsHXrVnTp0gWCIKBu3br4448/4O/vb647ciSwYIE2C4QOHgSaNFG/LhERERUcBkoVnT4N1K6tTW1BMB2BeOmSaSFLcnIyjh07liM8XrhwAQDg7OyMBg0a5AiPlStXhviY5dSJiYmoUKECevfujdmzZ8Pe3j7H8wkJQLVqQHKyekcwSpJpwdHq1erUIyIiIuthoFTR1KnA++9ru9VP9+7v4MKFjTh37hwURYGDgwMCAwNzhMeAgABIkvRMdbOysqDX6x/7/IoVwIABlnZvIkmmDd2jogBPT3VqEhERkfVwUY6KwsK0H+PUqRLo3LktJk2ahODgYNSoUQM6FfYUelKYBIBXXjFttj5tmmXjiKJpIc6mTQyTREREtoIzlCqqVg04f167+no9MGkS8OWX2o3xJIoCfPSRaXxRfPYzyCUJcHEBNm8GmjbVpkciIiIqeDyjREWpqbYxxuMIAvDFF8COHUCZMqbPBeHpX5c9gfr886ZjJxkmiYiIbAsDpYqectVYFXZ22o/xNO3bm4Lh7NlAQMC/j+v1//7KvoVTFIFu3YCdO4H1601bEBEREZFt4T2UKqpSxXTkolY3ERgMQMWK2tR+Vs7Opu2ERowwhcvwcNM9lvfvm8Kkr6/ptKCGDXmvJBERka1joFRRo0bAnj2WH7f4OIpiCmmFiSAANWqYfqm1CpyIiIiKFl7yVlHr1tqFSQBwcgLq1tWuPhEREVF+MFCqqH17oFw5bWrrdMDrrwMP7TlOREREZHUMlCqSJGDChLytfH5WsgyMGqV+XSIiIiJLMVCqbMwYoGbNf1c5q0EQgHffNe1zSURERFTYcGNzDURGmhboGAyWr/jW6YCqVYFjx4ASJVRpj4iIiEhVnKHUQP36wNq1pllKSy5/63SmDcS3bWOYJCIiosKLgVIDd+/excaNb6Br1zlwd8//5e/69YFDhwA/PzW7IyIiIlIXA6WKzpw5gxEjRsDHxwcLFizAyZPfIioKeOEF0/O6POz6KYqm03CmTjWFSV9fbXsmIiIishQDpQq2bNmC9u3bo1atWli4cCEyMzMBAEOGDEHp0sBvvwGnTgHDhwMlSz6+TkCAKUjGxQGTJqm7sIeIiIhIK1yUY6GzZ8+iZs2aj3zuwIEDaNasWY7HFAW4ft20cCcpyRQafXyABg0AN7cCaJiIiIhIZQyUFlIUBZ9++ik+//zzHI/b2dkhOTkZdnZ2VuqMiIiIqGDwkreFBEHAZ599hpCQEACAKJp+Sxs3bswwSURERMUCA6UKFixYgM2bN2PixIko+f83SbZp08a6TREREREVEAZKC+3atQujRo3C6NGjMW3aNERERODll1/GgAEDrN0aERERUYHgPZQWOH/+PJo0aYKGDRti06ZN0OVlXyAiIiIiG8NAmU+JiYlo0qQJdDodQkND4e7ubu2WiIiIiKyCU2r5kJWVhZdeegmJiYk4fPgwwyQREREVawyUz0hRFIwePRr79+/Hzp07UblyZWu3RERERGRVDJTP6IcffsCCBQuwZMkStGzZ0trtEBEREVldsb+H0igbkWnMhJ1kB0l88lmHGzduRPfu3fHOO+/g66+/LqAOiYiIiAq3Yhco07LS8OvpX/H3pb9x6PohxNyLgQLTb0E513Jo6tcU7Su1R7/a/eBSwsX8dSdOnEDz5s3x3HPPYd26deYNzImIiIiKu2ITKNMN6fhy35eYcWQG7mfchyRIMCrGXK+TBAmyIsNB74ARQSPwaZtP8eDeAzRq1AgeHh74559/4OTkZIXvgIiIiKhwKhaB8kjsEfRf3x+X716GrMh5/jpREOHj5AO3XW64d+wejhw5Aj8/Pw07JSIiIip6bH5Rzqbzm/DCmhcgK/IzhUkAkBUZ8SnxiAuOw+Q3JjNMEhERET2CTc9Q7r+6H+2WtYNBNpjvk8wvURDx58t/omtAV5W6IyIiIrINNhsokzOSUWN2DcSnxD/zzOSjCBDgbu+OqDFRKO1UWoUOiYiIiGyDzS5Vfm/ne0hISVAlTAKAAgX3M+5j3JZxqtQjIiIishU2OUN5+8FtlPm2DAyyQfXaAgRcGncJFUtWVL02ERERUVFkkzOUi48tVm1m8mGiIGJe2DxNahMREREVRTYZKDec3aBZoDQqRqw/t16T2kRERERFkc0FSqNsROSNSE3HuJR4CSmZKZqOQURERFRU2FygvJJ0BemGdE3HUKDg7K2zmo5BREREVFTYXKAsqJlDzlASERERmdhcoNSL+oIZRyqYcYiIiIgKO5sLlOXcykGAoPk4FdwraD4GERERUVFgc4HS2c4ZlUpW0nSMUg6lUNalrKZjEBERERUVOms3oIX2FdvjStIVTTY21wk6tPZvDUEwzYJmZGTgzp075l+lS5dGrVq1VB+XiIiIqLCyyUD5RtAb+CniJ01qGxQDhHAB9oPsIcsysrKycjzv6+uL2NhYTcYmIiIiKoxs7pI3AAT5BqGhb0PoRHXzsiRIqFKqCjoHdEZGRkauMCmKInr06KHqmERERESFnU0GSgD46fmfoPYx5UbFiEXdF2HY0GFYsGBBrudlWUb9+vUhy9qc0kNERERUGNlsoKzvUx+ftP5EtXoCBIxvPB6t/FsBAIYOHYr33nvv3+cFAQ4ODhg+fDiqVauG7777DomJiaqNT0RERFRYCYra03iFiKzIeP3P17E0cqlFdQQIeL7a81jXZ12Oy+iKouCVV17BmjVroCgKVqxYgfLly2POnDlYu3YtJElC3759MWrUKDRs2NC8kIeIiIjIlth0oARMofJ/2/+H6QenQxIkGBVjnr9WFETIioyhDYZiTsicR25mnpGRgeeeew7nz5/H1atXUaJECQDAzZs3sXjxYsyfPx8xMTFo0KABRo4ciX79+sHJyUm174+IiIjI2mw+UGbbG7MXg34fhCtJV54aLLODpLeTNxb3WIyQqiFPrJ2VlYWkpCR4enrmes5oNGLr1q2YO3cuNm/eDFdXVwwaNAgjRoxAjRo1LP6+iIiIiKyt2ARKAMgyZuGPqD8w68gs7L+6/5GhUhRENPRtiLGNxuKlmi+hhK6EauNHR0fjp59+wqJFi3Dr1i20adMGo0aNQs+ePaHX8yhHIiIiKpqKVaD8r3RDOk7cOIFzt88h3ZAOO8kOAR4BqOddD0522l6SzsjIwPr16zFnzhzs378fPj4+GDZsGIYNG4Zy5cppOjYRERGR2optoCwsTp48iXnz5uHnn3/GgwcP8Pzzz2PkyJHo0KEDRNFmF+ETERGRDWGgLCSSk5OxYsUKzJ07FydOnEDlypUxYsQIvPbaa/Dw8LB2e0RERESPxUBZyCiKgtDQUMydOxe//fYbBEFA3759MXLkSDRu3JhbDxEREVGhw0BZiN26dQtLlizBvHnzEB0djfr162PkyJF45ZVX4OzsbO32iIiIiAAwUBYJsizj77//xty5c7Fx40a4uLjg1VdfxciRI1GzZk1rt0dERETFHANlEXPlyhX89NNPWLhwIW7evInWrVtj5MiReOGFF2BnZ2ft9oiIiKgYYqAsojIzM7FhwwbMmTMH+/btg7e3N4YOHYo33ngD5cuXt3Z7REREVIwwUNqA06dPY+7cufj555+RmpqKrl27YtSoUejYsSO3HiKygsS0RFy4cwEZxgzY6+xRzaMa3OzdrN0WEZFmGChtSEpKClauXIm5c+ciMjISlSpVwvDhwzFkyJBHHgtJROqJiI/AnKNz8Pelv3H9/vVcz/u7+aNr1a4YETwCdbzrWKFDIiLtMFDaIEVRcOjQIcydOxe//vorAKB3794YOXIkmjZtyq2HiFR07vY5DP1zKA5cOwCdqINBNjz2tdnPt6/YHj89/xMqlaxUgJ0SEWmHgdLG3b5927z10OXLl1G3bl2MGjUK/fv359ZDRBZQFAUzDs/ApO2ToCgKDMrjg+TDdIIOOkmHmV1mYmiDoRp2SURUMBgoiwlZlrF9+3bMmTMHGzduhJOTEwYOHIiRI0eidu3a1m6PqEhRFAXv7XwP3xz4xuJaU9pNwXst31OhKyIi62GgLIauXr2KBQsWYMGCBbhx4wZatmyJkSNH4sUXX0SJEiWs3R5RoffjoR8x4e8JqtVb3H0xXgt8TbV6REQFjYGyGMvMzMTvv/+OuXPnYs+ePShdurR566EKFSpYuz2iQunsrbOoN68esuQs1Wo66BxwdvRZ+Lv7q1aTiKggMVASAODMmTOYN28eli1bhuTkZISEhGDUqFHo1KkTJEmydntEhUaLxS1w+PrhZ7pn8ml0og4dKnXA5v6bVatJRFSQGCgph9TUVKxatQpz5szBsWPHUKFCBfPWQ15eXtZuj8iqwuPCEbwgWLP658ecR1WPqprVJyLSCne9phycnJwwdOhQhIeH49ChQ2jdujU+++wzlCtXDv3798f+/fvB9yBUXM0NmwudqNOktiRImBc2T5PaRERa4wwlPdWdO3ewdOlSzJs3DxcvXkTt2rUxatQoDBgwAC4uLtZuj6jA+H3nh9jkWM3q1yxdE6dHndasPhGRVhgoKc9kWcbOnTsxZ84c/Pnnn3B0dMSAAQMwcuRI1K1bV7NxH2Q9QFhcGMLiwnD+znlkGDNQQiqBAI8ABJUJQsOyDeGod9RsfCIAuPPgDjynaXvilCRISHk/BfY6e03HISJSGwMl5cv169fNWw/Fx8ejefPmGDlyJF566SXVth66cOcCZh2ZhcWRi5GSmQJRECEJEhQoECDAqBghKzKc9E4YEjgEYxqNQYBHgCpjEz3s0PVDaLqoqebjnBl1BjVK19B8HCIiNfEeSsoXPz8/fPbZZ7hy5Qp+++03lChRAgMGDICfnx/effddREdH57t2ljELX+z7AjXn1MScsDlIyUwBAMiKjCw5CwbZgCw5C7IiAwBSs1Ix5+gc1JpTC5P3TkaWUb3tXIiyZRgyCmYcY8GMQ0SkJgZKsoher8dLL72EnTt34uzZs+jfvz/mzZuHypUrIyQkBH/99ReMRmOe6915cActFrfAx7s/hkE2PPFc5P8yKkYYZAM+2fMJmi1qhjsP7uT3WyJ6pIK6DM3L3URUFPGSN6nuwYMHWL16NebMmYPw8HD4+/vjjTfewOuvvw5vb+/Hft299HtouaQlzt46C6OS9xD6MEmQUM2zGva/th8lHUrmuw7Rf91Nu4tSU0tpOoZO1CHlvRSU0PHEKiIqWjhDSapzdHTEkCFDEBYWhiNHjqBdu3aYPHkyypUrh379+mHfvn25th5SFAWDfx9scZgETLOVUbejMOj3QdziiFRx5coVrFqyCg4ZDpqOU8OzBsMkERVJDJSkqYYNG2Lx4sWIjY3FN998g4iICLRu3Rp16tTB7Nmzcf/+fQDA6lOr8UfUHxaHyWxGxYi/zv+FVadWqVKPihej0YgDBw7g/fffR926dVGhQgWMHz8eJe+UhCRoc3KUJEgIqRqiSW0iIq3xkjcVKEVRsGvXLsyZMwd//PEH7O3t0a9/P6yvuB53M+5CgXp/HQUI8HT0ROxbsdBLetXqkm26d+8e/v77b2zcuBFbtmzBnTt34OnpiZCQEHTr1g0dO3bElfQrqDevnibjCxBwadwlVCxZUZP6RERaYqAkq4mNjcXChQvx4/YfcbfDXc3G+a33b3ip5kua1aeiSVEUREVFYePGjdi4cSP2798Po9GIevXqoWvXrujWrRsaNWqU6yz7dsva4Z+r/+R5wVhe6EQdng94Huv7rletJhFRQWKgJKsLWR6CbZe3qXa5+78kQUKHSh2wZcAW1WtT0ZORkYF9+/Zh06ZN2LhxIy5dugR7e3u0b98e3bp1Q9euXVGuXLkn1riUeAm159ZGuiFdlZ4ECHC2c8a5Mefg6+KrSk0iooLGQElWpSgKPKZ64G66djOUbiXccPd/dyEIgmZjUOF148YNbN68GRs3bsS2bduQkpICPz8/dOvWDd26dUPbtm3h6PhsJy39FP4Thm8crlqPq3qtwsu1X1atHhFRQdNZuwEq3mKTYzUNkwCQlJGEq0lX4e/ur+k4VDgoioJjx46ZL2UfPXoUgiCgSZMmeO+999CtWzfUqVPHojcYbwS9gZupN/HR7o/yXUOAAAUKfuz8I8MkERV5DJRkVQkpCQUyzs3UmwyUNiw1NRU7duzAxo0bsWnTJsTHx8PV1RWdO3fG2LFj0blzZ5QuXVrVMT9s9SHKOJfB2C1jzSc45ZUkSHDQO+Cnbj+hX51+qvZFRGQNDJRkVQV1x0X2MY3Z0tPTceDAAfzzzz94+eWXUb169QLpg9QTExNjDpC7d+9GRkYGqlWrhn79+qFbt25o0aIF9HptV/e/3uB1tK/UHiM2jsDfl/6GJEhPvBdYEiTIioznA57HrJBZKOtaVtP+iIgKCgMlWVVBnWTjbu+OM2fOYNu2bdiyZQv27t2LjAzTmcmlSpVioCwCDAYDDh06ZL6Uffr0aeh0OrRu3Rpff/01unbtiqpVqxZ4XxXcK2DrgK2Iuh2F+eHzsfXiVkTdicrxJkYSJNQoXQMhVUIwPHg4KpWsVOB9EhFpiYtyyKpkRYbLVy54kPVAszEcdA4ovbA0rsZcBQAIgpBjZnTPnj1o3bq1ZuNT/iUmJubYG/Lu3bsoXbq0eVufDh06wNXV1dpt5pKWlYbLdy8j05gJe509KpasyDO6icimMVCS1bVa0gr7r+5XdVPzbAIENCvXDM9dfQ6TJ0+GLMu5XtOnTx80adIEQUFBCAwMhIuLi+p9UN4oioKzZ8+aZyFDQ0NhNBoRGBho3tanYcOGEEUe8kVEVJgwUJLVzQ+bj5GbRmoWKOd0nYMRwSMQGRmJHj16IDY2Fkaj6T43FxcX1KpVC5GRkUhPT4cgCAgICECDBg0QFBSEoKAgNGjQoFDOgtmK9PR07N2717w3ZHR0NBwcHNChQwd07doVISEh8PPzs3abRET0BAyUZHUpmSnwnu6tyWVvR70jEt5OgEsJ06zjvXv3MGDAAGzatAkA0K9fP6xcuRIGgwFnz55FeHg4IiIiEB4ejsjISDx4YOqpatWq5oCZHTLd3NxU77e4iI+PN+8NuX37dqSmpqJ8+fLmvSHbtGkDBwcHa7dJRER5xEBJhcLX+7/G+zvfV/0s78ltJ+ODVh/keFyWZXz99df46KOPMGPGDIwePfqRX280GnHu3DmEh4ebfx07dswcMitXrpwrZJYsWTCLjIoaWZYRERFhvpQdHh4OURTRtGlTc4isVasWN58nIiqiGCipUDDIBjRa0AgnbpxQ5QhGSZBQ26s2wt4Ig0589GYG165dg6+vb66zmp/EaDQiKioqx0zmsWPHkJKSAgCoVKlSjoAZFBSEUqVKWfz9FEXJycnmvSE3b96MhIQEuLm5oUuXLujatSs6d+4MT09Pa7dJREQqYKCkQuNS4iU0XtgY99LvWRQqJUGCm70bDr1+CFU9tN9Gxmg04sKFC7lmMpOTkwEAFSpUyDGTGRQUBA8PjzzXN8gGHI09irC4MJy8eRLJmcmQBAnlXMshyDcITf2aFpr9DC9fvmzeG3LPnj3IzMxEjRo1zKuymzVrpvnekEREVPAYKKlQOXPrDNota4fbD27nK1RKgoRSDqWwe9Bu1PKqpUGHeSPLsjlkZs9kRkRE4P79+wAAf3//HLOYQUFBuU5yuZV6C3PD5mLO0Tm4kXoDAgRIomljbAECREFElpwFAQI6V+mMcY3HoVPlTgV62dhgMCA0NNR8Kfvs2bPQ6/Vo06aNeVV25cqVC6wfIiKyDgZKKnRupt7EiI0jsOHchqeePJIt+3U9q/fEvK7z4O3sXQCdPhtZlnHp0qUcM5kRERFISkoCAJQrV84cMlMqpmDutblIzUrNdcrPo2R//90CuuGnbj+hjEsZzb6PO3fuYOvWrdi4cSO2bt2Ke/fuwdvb2zwL+dxzz3HrJSKiYoaBkgqtP6P+xLQD07D/2n7z7Nx/z0vWiTrIigxZkdG8XHNMbDYRPar1KFILO2RZxuXLl83h8mj4UewvtR9ZtbIAGcAzbrcoCRKc7ZyxdcBWNPFrokqPiqLg9OnT5kvZoaGhkGUZQUFB5hAZFBTEvSGJiIoxBkoq9M7cOoMdl3cgPD4cp2+eRrohHfY6e9TyqoWgMkF4rtJzqFm6prXbtJisyBi4fiBWnVpl0Wp3SZBgJ9lh96DdaOzX+JGv2bdvHzZs2IBvv/32kUEwPT0du3fvNu8NeeXKFTg6OqJDhw7o1q0bQkJC4Ovrm+8eiYjItjBQEhUS34Z+i4nbJ6pSSxREeDh4IGpMVK7z0v/66y/06tULWVlZOHr0KIKDgwEAcXFx5gC5Y8cOPHjwABUqVDBv69O6dWvY2xe+4wNTM1NxP+M+BEFAKYdSsJPsrN0SEVGxw0BJVAhE3Y5C3Xl1kWnMVK+oDJRNLIshJYeYF/7s3r0bgwcPhqIoEEURr732GsqUKYNNmzYhIiICoiiiefPm5gU1NWvWLHS3EBhlIzZd2IQ1p9fg4LWDiL4XbX5OJ+pQ07MmWpRvgcH1B6Nh2YZW7JSIqPhgoCQqBF769SX8EfVHjntE1VJydUncPXf3sc+7u7ujS5cu6NatGzp37lxo981UFAVLI5fiw90fIi457okLtnSiDgbZgECfQMzsMhPNyzcv4G6JiIoX3kVPZGVxyXHYcG6DJmFSJ+rQe1pv9O7d+7GvEUURiYmJOH36NPbs2YMrV66gsL3PTEhJQJcVXTDkzyGIS44DgCeu/s/+vTxx4wRaLmmJt/5+S93ZXyIiyoEzlERWNj10Ov6343952h4oPxx0DvBa5IUr0VfMj+l0OhgMptD1/PPPQ5ZlhIeHIyEhAQDg4eGRY4/MoKAgVKhQwSqXv6/cu4JWS1shLjku36FbFEQ8V/E5/NHvD9jrCt99oERERR0DJZGVvfTrS9hwboNmgRIAjo84jkpOlXDq1CmcPHkSJ0+exLFjx3D69GlMmTIFI0aMAADEx8fn2CczPDwccXGmGcFSpUrlCpkVK1bUNGTeS7+HBvMb4FrSNRgUy2ZwRUFE92rdsb7P+kJ3XygRUVHHQElkZeW/L49r969pOsaSHkswuP7gfH1tQkJCrpAZGxsLwHT/5cMhs3LlyqoFtkG/D8KKEytUOd8928LnF+L1Bq+rVo+IiBgoiazO8UtHpBnSNKuvE3X4st2XeKf5O6rVvHHjhvlIyexf166ZQrGbm9sjQ+azbny+7dI2dFreSbWesznpnXBx3EX4OPuoXpuIqLjSWbsBouLOkk3M80rty+ne3t7o0qULunTpYn7s5s2bOULmr7/+iunTpwMAXF1dzSEz+79Vq1Z9Ysj8ev/XeT5681mkGdLwU/hP+Lj1x6rWJSIqzjhDSWRlZb4tg4SUBM3qCxAwv9t8DAsaptkYj3P79u1cM5kxMTEAABcXFwQGBuaYyQwICIAoijh/5zyqzaqmWV9eTl6IfSsWOpHvqYmI1MBASWRl3Vd1x6YLmzRdlHN02FEE+wZrVv9Z3LlzJ1fIjI42bU7u7OyMwMBAiE1F7HPcp+nsbfgb4WhQpoFm9YmIihO+PSeyskZlG2Hzhc2a1deLetTxqqNZ/Wfl4eGBDh06oEOHDubHEhMTcezYMXPA3By/GagEQMPF2OFxDJRERGrhxuZEVta3Vl/V7xPMphN16FWjF0roSmhSXy2lSpVC+/bt8c4772DNmjWo1KwSFEG72Um9qMfpW6cf+VxqaioSExM1G5uIyBYxUBJZWVWPqmhXoR1EDf53NMgGjG40WvW6WkvL0m7V+6PGSEtLw7p169C7d294eHigWbNmmo9PRGRLeMmbyMoOHz6Ma0uvQW4tq3qJVyfq0L5iezQvV/TOsdZLes3H0Ik6zJ07Fzt27MDmzZuRnp5uPkHIxcVF8/GJiGwJZyiJrOTevXsYNWoUmjZtCuckZ7xa+VUIKiVKAQLsdfZY1H1RkTwVpppHNYiCdj+ejIoRty/cxqhRo7B+/Xqkp6cDAAwGAwRBgF6vR2hoKG7cuFHozjUnIiqMOENJVMAURcHKlSvx1ltvIS0tDT/88ANGjRoFI4y4svwK9l/db9E9lQIEiIKIVb1WoaxrWRU7LzjBvsH4M+pPzerLioyRPUaifGx5fP/991AUBbJsWmWvKAoOHjyI5s1NM7vOzs6oXLkyqlSpgipVqpg/rly5Mvz8/J55w3YiIlvEbYOIClBUVBRGjRqFXbt2oU+fPvj+++/h6+trfj41MxU9VvfAruhd+doyRyfqIEDAr71/Rc/qPVXsvGCFXgtF88XaXap30Dng1qRbcLJzwpkzZ/DKK6/gxIkT5tnIhQsXolGjRrh48SIuXbqU479Xr141h88SJUqgYsWKOYJm9scVKlSAXq/9pXtbpihAdDRw5gyQlgbo9UClSkDNmoCO0yFEhQoDJVEBSEtLw1dffYVvvvkGfn5+mD17Njp37vzI1xpkA6YdmIaP93xs/vxpsi+V1/Wui+UvLkdtr9rqNW8FiqKg5pyaiLodpfpelDpRh2ENhmFO1znmx7KysjBlyhR8/vnnkGUZoaGhaNq06SO/PjMzEzExMeaA+d+wGR0djczMTACAJEkoX778I8NmpUqV4OjoqOr3ZSsUBQgNBWbPBjZuBJKTc7/Gzg5o3hwYPRro3t0UNInIuhgoiTT2999/Y/To0bh69SreffddvPfee3BwcHjq1529dRbTQqdhxckVyDRmQi/qkSVnmZ+XBAkKFMiKjGoe1TChyQS8Hvh6gSxoKQgLIxZi2F/qn+4jQMDJkSdRy6tWrufCwsKwfPlyfPPNNyhR4tm3WjIajbh+/fojw+alS5eQmppqfq2vr2+uS+jZ/3V3d7fkWyyyzp0DBg8GDh82zUAanvBeSpIAoxEoWxZYtAjopP6x70T0DBgoiTQSFxeHt956C2vWrEHbtm0xZ84cVK9e/ZnrJKYl4u+LfyM8PhyRCZFISk+CTtKhontFBJUJQvPyzdG4bOMiufjmSYyyES2WtEBYXFieZmnzQhRETGw6Ed90+EaVes9CURTcuHEj1yX07I//u/elh4fHY8Oml5eXzf1ZA8CcOcCECYAsm4JiXomi6WveeAOYNYuzlUTWwkBJpDKj0Yg5c+bggw8+gL29Pb777jv079/fJkOA1s7fOY/68+ojw5hh8dGUOlGHyiUrI3JEJOx19ip1qJ67d+/mCpvZ/42Pjze/ztnZ+bFhs6guEvryS+DDDy2rIQhA167A+vUMlUTWwEBJpKKwsDCMGDECERERGD58OKZMmYKSJUtau60ibU/MHnRe3hlZcla+Q6VO1MHXxRcHhhyAn6ufyh1qLzU1FZcvX37kzObjFgk9HDYL6yKhX34BXn1VnVqCYJqpnDdPnXpElHcMlEQqSEpKwgcffIA5c+agbt26mDdvHpo0aWLttmxG6LVQvPTrS7iZejNfWyo1LtsY6/uuh6+L79NfXMRkLxJ61MxmYV8kFBsLVK8OpKaaFuOo5e+/gY4d1atHRE/HQElkAUVRsGbNGrz55ptISUnB559/jrFjx0LHPU1Ul5SehInbJ2JRxCKIgvjEYJm96r2ErgS+bPclxjceD0mUCqrVQiN7kdCjwmZhWCTUuzfw++9PXnzzrEQRKFPGtN1QIZyQJbJZDJRE+XThwgWMGjUKO3bsQK9evfDDDz/Az6/oXU4tamLuxeCn8J/wy4lfcP3+9VzPi4KImp41MSxoGAbVGwQ3ezcrdFn4WXuR0PXrgL+/aUGNFtatA158UZvaRJQbAyXRM0pPT8c333yDr776CmXKlMGsWbPQtWtXa7dVLN15cAfHbxzH3bS7EAURPs4+qOdTD4567vFoqWdZJJSfk4Q++wyYPPnZVnTnlSQBrVsDO3eqX5uIHo2BkugZ7NixA6NGjUJMTAwmTZqEDz74gBtUU7HzqEVCz3qS0JAhlbF/v3Yr0kuUAFJSeKIOUUFhoCTKg4SEBLz11ltYtWoVWrVqhblz56JmzZrWbouo0MnbSUICgPsAnDXt5cQJoE4dTYcgov/H925ET2A0GjF//ny8//770Ov1WLp0KV599VXuKUn0GHZ2dggICEBAQECu57IXCUVEXMWLL2obJgHg8mUGSqKCwkBJ9BgREREYMWIEjh49iqFDh+Lrr7+Gh4eHtdsiKrIkSYK/vz/s7PwLZLz/3zHpoccyceTIEVStWhXe3t4F0gdRcVD0jlQg0tj9+/cxfvx4NGzYEOnp6di/fz8WLFjAMEmkkjwcZa8KR0fTavbz589j5syZCAkJgZubG1q2bIlp06YVTBNExQRnKIn+n6IoWLt2LcaPH4+kpCR88803GD9+fKE8XYSoKHN3Bzw9gdu3tR1n1aqP0Lfv90hNTYUgCBAEwbxgqHLlytoOTlTMcIaSCMClS5cQEhKCPn36oHHjxjh79iwmTpzIMEmkkUaNTJuQa8XVFQBizJu3K4piDpMAEB0djcOHDyMtLU27JoiKEa7ypmItIyMD06ZNw5dffgkvLy/MnDkT3bt3t3ZbRDZv7lxg9Gh1j1zMptMBffoAK1YA69evx8CBA5GRkQHjfza9lCQJRqMRkiShRo0aCAoKQoMGDdCgQQPUr18fzs7aLxoisiUMlFRs7d69GyNHjsSlS5fw9ttv46OPPoKTk5O12yIqFpKTAR8f4MEDbeofOAA0a2b6+Pz58+jRowfOnz8PWZZRvXp1REZG4tSpUwgPD0dERATCw8Nx4sQJZGZmQhAEVKtWLUfIDAwMhJsbT10iehwGSip2bty4gYkTJ2L58uVo0aIF5s6di9q1a1u7LaJi53//A6ZPV/f4RZ0OaNjQFCj/u7tXamoq3njjDaxcuRKDBg3C0qVLc31tVlYWzpw5Yw6ZERERiIyMNF8Wr1KlCho0aJAjaJYqVUq95omKMAZKKjZkWcaCBQvw7rvvQhRFTJs2DYMHD37s0XBEpK0HD4DatYGrV9U7gtHODjh5EnjENphQFAV//vkn6tSpg0qVKuWpnsFgQFRUVI6QeezYMaSkpAAAKlSokCtkenl5qfPNFDJ37gDh4UBEBHDzpul2BQ8PoH59IDjYNONMxRcDJRULx48fx4gRI3Do0CEMGTIE33zzDTw9Pa3dFlGxd/gw0KoVkJWlzv2Uc+cCI0ZYXudJZFnGhQsXzJfKs4NmUlISAMDPzy9XyPT19dW2KY0oCrBtGzBrFrBpk+lzSfp3QZWiAAaD6ePWrYGxY4EePXjkZXHEQEmFRlpWGs7fOY+UzBToJT0quldEaafSef76+/fvY/bs2Rg9ejRcTUs8kZycjE8++QQzZsxA9erVMXfuXLRs2VKrb4GI8mHrVlMIMRrzN1MpCKZg8+WXwPvvq99fXiiKgsuXL+cImeHh4UhMTAQA+Pj4mMNldtAsV65coT516+pV4PXXgR07TAExOzg+jiSZ/vyCgoCffwZ4Om3xwkBJVnU16Srmh83HhnMbEHUnCrKS82YqH2cftKvYDiOCRqBF+RZP/OE7evRozJkzB2PGjMGMGTOwYcMGjBs3DomJifjkk0/w5ptvws7OTutviYjy4fBhoF8/4MqVZ7unUpJMG6XPnQsMGKBdf/mhKAquXr2aK2TevHkTAODp6ZlrJrNixYqFImRu3Qq89BKQkfH0IPmw7NnJRYuAV19VvzcqnBgoySpuP7iN8VvHY9XJVRAFEUbl8dMSOlEHg2xAba/aWPj8QjT2a5zrNUeOHEGTJk2gKAoEQUCzZs1w4MABdOvWDTNnzkSFChU0/G6ISA0PHgCffw7MnAmkpZlmHh8XLiXJNCvZqxfw/fdA2bIF22t+KYqCuLi4XCEzLi4OAODu7p5rJrNKlSoFeq/3li1A9+6m33tLF0wtXgy89po6fVHhxkBJBW7LhS0YsGEAktKTnhgkHyYJEmRFxrst3sXktpMhiRIA003zgYGBOHv2rHmfOb1ej1WrVuHFF18sFO/2iSjvkpNNe0hu2mSaubx169/nnJ2BBg2A9u1Nl2OLSpB8moSEBBw7dizHPZlXrlwBALi4uCAwMDDHTGa1atUgSZLqfVy+bFoolZ6uzj2tggAcPAg0zj0PQDaGgZIK1OpTq9F/fX8oigIF+furJ0BA39p9sfyF5ZBECT/88APefPPNXK+bOXMmxowZY2nLRGRlSUmm2Us7O6BUqZzbAdmy27dv5wqZly5dAgA4Ojqifv36OUJmzZo1obNgNYwsmxbWHDr07Je5H0eSgIoVTSvv7e3VqUmFEwMlFZjd0bvx3C/P5bpPMj8ECBjXeByG+w9HnTp1cpyAIQgCFEWBk5MTkpKSNHkXT0RkDXfv3kVkZGSOkHn+/HkoigJ7e3vUrVs3x+Xy2rVr5/ne8bVrgd691e9ZEEz7jb71lvq1qfBgoKQCkZyRjBqzayA+JV6VQJmtv6E/VnyxAnZ2dvDx8YGPjw/Kli0Lb29v1KpVC6NGjeI+k0Rk05KTk3OFzLNnz0KWZej1etSpUydHyKxbty7sHzFd2KoVEBqq3p6g/1WhAnDpkrbnt5N1MVBSgXhz65uYcWSGqmFSFESUdSmLsyPOwsmBRyYSEWVLTU3FiRMncoTM06dPw2AwQJIk1KpVK8flcje3+qhd21HTnvbuNYVWsk0MlKS5+xn34TPdB2mGNE3qr+29Fr1q9tKkNhGRrUhPT8fJkydzrDA/efLk/59f/goUZYVmY0sSMGUK8M47mg1BVsa97ElzK06sQLohXZPakiBh5pGZDJRERE9hb2+Phg0bomHDhubHMjMzcfr0abz7rg47d8owGrW7Jh0erllpKgQYKElz2y9vNy+UUZtRMeLAtQPIMGSghK6E6vWJiGyZnZ0dAgMD4empzjZBj2M0AteuaVefrI+3x5LmDsceVvXeyYcZZANO3TylWX0iIlunxUIca4xB1sNASZrKMGQgLjlO83Gi7kRpPgYRka1ydzfd56gVQTDtIUq2i4GSNJVpzCyQcTIMGQUyDhGRLapXT73NzB9FkoDAQO3qk/UxUJKmCuq+Rnsdj2AgIsqv4GBt76E0GICgIO3qk/UxUJKm7CQ7lHXR/rDdap7VNB+DiMhWBQUB5cppV9/JCejUSbv6ZH0MlKS5xn6NIQra/VXTiTrU9qqtWX0iIlsnisDYsdqcZKPTAUOGAM7O6temwoOBkjTXsVJHTbYMAkz7ULYs3xJ2Ut7OqiUiokcbNgzw9FQ/VOr1wNtvq1uTCh8GStLcK3VegYPeQZPaRsWIsY3GalKbiKg4cXcHFi8GZJV3efvuO8DfX92aVPgwUJLmXEq4YGTwSNUve0uChAruFfB8tedVrUtEVFx17QpMnKhOLVEE+vYFhg9Xpx4VbgyUVCA+bfMpyrqUVTVUGhUjlvVcBp3IA5+IiNQydSowYYLpY0HIf51evYCff7asBhUdDJRUIJztnLHixRUQBREC1PnpMrHpRLTyb6VKLSIiMhEE02XqX34BXFxMi2rySqcDSpQAfvgBWL0asOPt7cUGAyUVmJb+LbG612pVQuWgeoPwTYdvVOqMiIj+SxCAAQOAc+dMl6wdHU2P6/W5X6vXm16v1wP9+gEnTwLjx2uzYpwKL0HRavkt0WP0ebcPfjP+BtFFfKYzviVBggIFH7X6CB+3/ljTrYiIiOhfycnA778DR44Ahw8DN26YNkL38FBQp046WrZ0wIsvAh4e1u6UrIWBkgrU33//jc6dO+PzaZ8jJiAGyyKXQYHyxGCpE3UwyAYE+gRiYfeFaFCmQQF2TEREjzN58mR8/PHH2L17N9q0aWPtdsiKGCipwMTHx6NevXoIDg7Gxo0bIYoi4pLjsDBiITac3YDTt04jS87K8TX+bv5oV7EdRgSPQEPfhhB4dzcRUaHRvn177Nq1C97e3jh//jxcXV2t3RJZCQMlFQhZltGpUyecOnUKx48fh5eXV67XZBozcSnxElKzUqEX9fB394e7vXvBN0tERE+VkZGBkiVLIi0tDaIo4qWXXsLq1av5xr+Y4n4rVCCmTp2KnTt3Yvv27Y8Mk4Dp3O8apWsUcGdERJQfe/fuRVpaGgDTpMGvv/6KTp06YciQIVbujKyBqxpIcwcPHsSHH36I999/H+3bt7d2O0REpII///wTuof2FBo1ahTOnDljpY7ImnjJmzR19+5dBAYGomzZsti7d2+uHz5ERFT0KIoCPz8/xMXFmR/T6XQwGAwYOnQoFixYYMXuyBr4rztpRlEUDBs2DElJSQyTREQ2JCUlBfHx8RAEAZ6enrh16xbGjRuHRo0aoUOHDtZuj6yA/8KTZn766SesW7cO69atg7+/v7XbISIilbi4uCAhIQHOzs6IiYlBrVq10L17d7Ru3drarZGV8B5K0sTJkycxYcIEjBw5Ei+++KK12yEiIpV5eXnB0dERVatWhV6vx6lTp6zdElkRAyWpLjU1FX379kXVqlXx7bffWrsdIiLSkF6vR/Xq1XH69Glrt0JWxEvepLoJEybgypUrCAsLg4ODg7XbISIijdWuXZszlMUcAyWpas2aNVi4cCEWLlyIGjW4pyQRka2LiwMUpTeOHLmG3r0VZGUJcHAAatYEgoOBli0BZ2drd0la47ZBpJrLly8jMDAQISEhWLlyJU9LICKyYbt2AT/8AGzcCCgKIAgGABIURYAkmV5jNAKOjsDgwcD48UBAgBUbJk0xUJIqsrKy0KJFC9y+fRsRERFwc3OzdktERKSBxERg7Fhg5UpApwMMhqd/TfaucV98Abz99r+fk+3gHymp4sMPP0RERAQOHDjAMElEZKNOnwbatwdu3zZ9npcw+d/XvfcesGmTaVbT1VWbHsk6uMqbLPb3339j6tSp+Oqrr9CoUSNrt0NERBqIijLdD3n7tulSdn4oChAaCnTsCKSmqtsfWRcveZNF4uPjUa9ePQQFBWHTpk0QRb5HISKyNRkZQN26wKVL+Q+T/yVJwJAhwE8/WV6LCgf+60/5JssyXn31VUiShGXLljFMEhHZqM8+Ay5cUCdMAqY6CxYA27erU4+sjwmA8m3q1KnYuXMnfvnlF3h5eVm7HSIi0kBCAjBtmulytZpEEXjzTfXrknUwUFK+HDx4EB9++CHee+89PPfcc9Zuh4iINLJwISDL6teVZdMin0OH1K9NBY/3UNIzu3fvHurXrw9fX1/s3bsXer3e2i0REZFGKlUCoqO1qa3TAUOHAnPnalOfCg63DaJnoigKhg4diqSkJOzZs4dhkojIht29q12YBEzbCYWGalefCg4DJT1Vnz59ULJkSXz33XdYvnw51q1bh7Vr16JChQrWbo2IiDQUGan9GGfOAJmZgJ2d9mORdhgo6YkyMjKwfv16GI1GbN26FQkJCRgxYgR69epl7daIiEhjt25pP4bBACQnAx4e2o9F2mGgpCc6f/48jP+/T8TVq1cBANWrV4eiKDyrm4jIxhXUKguu5ij6uMqbnujUqVO5HpswYQIGDx5c8M0QEZHqjh8/jv/9739YvXo1YmJi8N+1up6e2o8vSYCLi/bjkLY4Q0lPdPr0aUiSZJ6lzP74wYMHVu6MiIjUsHPnTkydOtX8ealSpdCsWTNUrVoVjRuHANB2a7hq1YASJTQdggoAA2UxczHxIn4/9zvC48IRkRCB5Ixk6EQd/N390ci3EZqXb45uAd1gJ5nujj506BCMRiMEQYCiKGjSpAm++uortGzZ0srfCRERqeHhn+eJiYnYuHEjAMDFZSHKlbuPa9e0GVunA5o106Y2FSzuQ1lM7LuyD5P3TsaO6B0QBRECBBiVnGdo6UU9suQseDh4YHTD0ZjUfBK83L2QlpaGwMBATJ06Fe3bt+e9k0RENiAuLg67d+/Gzp07sXTp0hyXugVBQOnSpbF161Zs2BCIKVPUO3bxYXv2AK1ba1ObCg4DpY1LyUzBO9vfwdywuZAEKVeIfBxREFHWpSwaXm+IDlU7YPjw4QySRERF2K1bt7Bnzx7s3r0bu3btQlRUFACgVq1aSE1NxZUrV6AoCkRRRMOGDbFx40Z4enri+nXA31/903IEAahaFTh3zvQxFW1clGPDbqXeQrNFzTA/fD4A5DlMAoCsyIhNjsUG1w2QGkoMk0RERcy9e/fwxx9/YMKECahbty68vLzQp08f7NixA23atMHq1auRkJCAU6dOYdy4ceave/HFF7Fnzx54/v+KHD8/YNw409nbalIUYPp0hklbwRlKG3U/4z6aL26Oc7fOwaAYLK63rOcyvFrvVRU6IyIiLSQnJ2P//v3YtWsXdu/ejYiICCiKAn9/f7Rr1w5t27ZF27Zt4efnl+trz549i7p16+Ktt97CV199BfGh9PjgAVCrFnDtmjqXviUJ6NcP+OUXy2tR4cBAaaOG/jkUSyOXPtOs5JOUkErg5MiTqOpRVZV6RERkmbS0NISGhpoD5JEjR2A0GlGmTBlzgGzXrh0qVqyYp3qpqalwcnJ67PMnTgAtWpjCpSWhUpKA2rWBvXsBN7f816HChYHSBm2/tB0dl3dUtaZO1CHYNxgHhhyAKPBOCSIqeu6m3cWmC5sQFheGYwnHkJiWCEmQUN6tPIJ9g9HUrynaVWwHSZSs3eojZWZm4vDhw+YAefDgQWRmZsLT09M8+9iuXTsEBARodptSeDjQoQNw/37+QqUgAIGBwLZtPBnH1jBQ2qAmC5vgaNxRyIrKd1AD2D5wO56rpO2eZEREajp/5zy+3v81VpxcgUxjpnlHi2z/3fmirEtZjGk0BuMaj4Oj3tGKXQMGgwHh4eHmALl//36kpaXB3d0drVu3NgfIWrVq5bpEraX4eGDYMGDTJtNsY16CpU5nWtTz7rvAxx9z30lbxEBpYyITIhE4P1CT2jpBh64BXfH7y79rUp+ISE1G2YgfDv2A93e9D1mRYZDzdj+5KIjwd/PHLy/8gublm2vc5b9kWcbx48fNAXLfvn1ITk6Gk5MTWrZsiXbt2qFdu3aoX78+JMm6s6iKAvz5J/D996ZL1wCg1wNZ/+Z08+d6PdC3L/D220D9+lZplwoAA6WN+WDnB5gaOjXPPziflSiISHkvBQ56B03qExGpIS0rDb1/641NFzbl6+slQYKsyJjfbT6GBQ1TuTsTRVFw5swZc4Dcs2cP7t69C3t7ezRv3tw8AxkcHAy9Xq9JD2q4cAHYt890OfziRSAjA3B2Nt0nGRQEtGtXMEc4knUxUNqYDr90wM7LO6FAuz/Wg68fRBO/JprVJyKyhEE2oMeqHth6aasqt/4s6bEEg+sPtriOoii4ePGiOUDu3r0bN2/ehF6vR5MmTcwBskmTJijBa8JUxPDoRRtzLP6YpmFSgIDIhEgGSiIqtL7Z/w22XNyi2s/CYX8NQ6OyjVCzdM1n/torV66YA+SuXbsQGxsLSZIQHByMIUOGoF27dmjWrNkTV1cTFQUMlDYmJTNF0/qSKOF+xn1NxyAiyq9TN0/h072fqv7GeuCGgTgy9MhTV4BnH2eYHSCjo6MhCALq16+Pvn37ol27dmjZsiVcXV1V7Y/I2hgobYzWJ9ooigJJKJxbahARfb73c9VrGmQDIuIj8Nf5v9Czes8cz92+fRt79uzBrl27ch1n2LVrV7Rr1w6tW7dGqVKlVO+LqDBhoLQxPs4+iLkXo1l9o2JEGZcymtUnIsqv+OR4rD+7XrUDHf5LEiTMODwDbXzaYO/eveZZyBMnTgAAqlatirZt2+Kzzz5DmzZt4O3trXoPRIUZA6WNaVy2Ma4lXdPkB2q2oDJBmtUmIsqvdWfXaXYPuVExYnfMbpQqVwpKioLy5cujXbt2mDhx4mOPMyQqThgobUxTv6b47cxvmtV3K+HG4xeJClh8cjxupN6Aoihwt3dHBfcKmt/eUhQdjTsKURA1OdQh2/ivx2Nsl7GoWLEi/wyI/oOB0sa8UucVTNw+UZMfqJIgYWiDoTx6kUhjBtmAjec3YknkEoReDcXttNs5nnexc0GwbzD61+mPfnX6Wf1El4J09+5duLu7PzLMHYk9otkevIDpZ6BXXS9UqlRJszGIiiomAxtT2qk0Xq79MnSi+u8VZEXGiOARqtclon/9evpXlP++PF5Y8wI2nd+UK0wCQHJmMvZe2Yuhfw2Fz3QfTA+dDqOs3W0uhcW1a9dQqlQpVKpUCZ988ol5AUy2e+n3NB1fFETcTb+r6RhERRUDpQ2a0m4KSkjqboorCiLebPImqpSqompdIjJJSk9Cr197oe/avkhISQCAJ94LnX0VIjkzGZO2T0LTRU0RfTe6QHq1Fnt7ewBATEwMvvzyS1SvXh3169fHtGnTTNvzQPtL0LxCQ/Ro/D/DBpVzK4cfO/+oWj1JkODv5o/J7SarVpOI/pWYloiWS1rij3N/AEC+FpZExEeg8cLGiLod9fQXFzEGgwFXrlzB6dOnzUcQGo2msH38+HG88847qFKlCrydtV1ZbVSM8Hbi6m2iR+E9lDZqSOAQnLp5Cj8c/sGiOjpRB9cSrtg6YGuxuk+LqKBkGbMQsiIEZ26dsWh3BqNiRGJaItoua4sTI0/A07HoHJ5sMBgQFxeHmJgYxMTEIDo62vxxTEwMrl27Zg6QDxMEAQ4ODvjss89wsexFnLp5SrP7KGVFRoMyDTSpTVTUMVDaKEEQ8F2n7+Cod8SU/VPytfJRFESUcS6D7QO3I8AjQKNOiYq3qQem4kjsEVW2uzEqRtxMvYnRm0ZjTe81KnSnDqPRiNjY2Bwh8eHAaDD8GwJ9fHxQoUIFVKhQAU2aNDF/XKFCBYwbNw7btm2DIAhQFAU9e/bEvHnz4OXlhaWRS/FT+E+afR+SICGwTKBm9YmKMkFRFO0OfqZCYVf0Lgz6fRCu378OESJkPDlY6kQdDLIBI4NHYmqHqXC2cy6gTomKl4uJF1Fjdg1NZtQ29tuIrgFdVa/7KM8aGL29vXOExP/+8vf3h4ODw2PHGj16NObMmQN3d3fMnz8fffr0MT93P+M+vKd7I92Qrvr3qBN1eLH6i4UqqBMVJpyhLAbaVWyHqDFRWHlyJX48/CNO3TwFwPQDMvsm9ixjFiAA9jp7DKo3CKMajkJd77rWbJvI5s06MgtavKeXBAnTQqepFiiNRqP5kvTDl6MfFRhLly6NihUromLFimjUqFGOwFi+fHk4Oub/9plXXnkFgiDg448/hpeXV47nXEu4YnC9wVgQsUD1wx0MsgGjG41WtSaRLeEMZTGjKAquJl1FeHw4Ttw4gZTMFBiyDPjxsx/x6fBP8c6r78BB//jZASJSx4OsB/Ce7o2UzBTNxjg7+iyqe1Z/6uv+Gxgf9evq1as5AqOXl9cTZxgtCYyWik+OR/XZ1ZGckazaqTmSIKFbQDds6LuBm5kTPQZnKIsZQRDg7+4Pf3d/vFjjRfPja4augXxVZpgkKiBHY49qGiYFCNhxeQeqe1a3KDAGBwcXqsD4NGVcymB2yGwM3DBQlXqiIMLZzhnzu81nmCR6AgZKAgBUq1YN58+ft3YbRMVGeHy4pscEihDx5ZIv8X2/73MFxtKlSz82MJYvXx5OTk6a9FRQ+tfpj2Pxx/Ddoe8sqiMKInSiDn+8/IfmWxIRFXUMlAQACAgIQFhYmLXbICo2om5HQRIkzQKlEUZkuGZgYK+BuWYYi3pgfBpBEDC943TYSXb4+sDX+QruOlEHe509NvbbiNYVWmvUKZHtYKAkAKZAuXLlSiiKwss6RAUg3ZiuWZjMVrZCWUwdOVXTMQorQRDw1XNfoW3Fthj8+2Dz6UNPu69SEiQYFSOeq/gcFnZfiLKuZQuiXaIijyflEADTJe/U1FTEx8dbuxWiYqGEVELzN2/2kr2m9YuCjpU7ImpMFH7o/AMqlaxkflwv6qETdeZfgOm+046VO2LTK5uwuf9mhkmiZ8AZSgJgmqEEgKioKPj6+lq5GyLb8M8//+DYsWOoV68e6tWrB3d3d/NzAR4Bms5Q6kQdanrV1Kx+UeJSwgXjGo/D2EZjcfLmSYTHhSMyIRL3M+9DEiSUcS6DIN8gNC7bGGVcyli7XaIiiYGSAACVKlWCJEk4f/482rZta+12iGzCzJkz8dtvv5k/L1OmDOrXrw8PDw/Ueb6OpoHSKBsRVCZIs/pFkSAIqOtdl3vsEmmAgZIAAHq9HpUqVUJUVJS1WyGyGe3atcsRKOPj4823ldQ+UxuOvRzxIOuBJmMrUNC+YntNahMRPYz3UJJZQEAAtw4iUoHBYMA///yD48eP53pOEAQ0btwYB/cexGv1XzPfv6cmURDRvFxz1PKqpXptIqJHYaAks2rVqnGGkiifbty4gWXLlqFv377w9PREq1atsH79eri6uppfIwgCevXqhX379sHZ2RljGo3R5OhFWZExsdlE1esSET0OAyWZBQQEIDo6GpmZmdZuhajQk2UZR44cwaeffoqGDRvCx8cHr732GmJiYvDmm2/i6NGjiI+Px/Dhw82ruYcNG4bVq1fDzs4OAFDdszo+aPkBBKi32lsSJPSo1gM9qvVQrSYR0dPwLG8y27NnD9q2bYuzZ8+ievWnn/9LVNwkJiZi27Zt2Lx5M7Zu3Ypbt27B3d0dnTt3RkhICDp16gQvL68cXxMaGormzZvj/fffxxdffJFrq6BMYyYaL2yMUzdOwaAYYAlJkFDSoSROjjwJH2cfi2oRET0LBkoyi4uLQ9myZfHHH3+ge/fu1m6HbFhcchwu372MLGMWnOycUMOzBlxKuFi7rVwURcGJEyewefNmbN68GaGhoZBlGfXq1UNISAhCQkLQpEkT6HRPvg/y5s2buYLmf91KvYWWS1riYuJFGBVjvnqVBAmuJVyx77V9qO1VO181iIjyi6u8yaxMmTJwdnbmfZSkOkVRsDtmN+aFzcPu6N24nXY7x/MCBFQsWREvVH8BI4JHoEqpKlbqFEhOTsaOHTvMITIuLg7Ozs7o0KED5s+fjy5duqBs2Wfb8PpJYRIASjuVxoEhBzBg/QBsvbQVAoSnnujyXwIE1CxdE2v7rEWAR8Az9UZEpAbOUFIOQUFBaNCgARYsWGDtVshGHLh6AK//+Tqi7kRBJ+pgkB9/WTf72LteNXphdshseDt7a96foiiIiooyB8h9+/YhKysL1atXN89CtmjRAiVKlCiQXn458Qve/PtNJKYlPvEM6uz7LkvoSuD9Fu/j3RbvQi/pNe+RiOhRGCgph379+iEuLg579+61ditUxBllI97b+R6mh06HKIjPdClXEiQ42zljac+l6Fm9p+q9paWlYffu3eYQGR0dDXt7e7Rt29YcIitVqvT0QhrJMGRg/dn1WHxsMQ7HHkZyZnKO50tIJVDfpz4G1B2AV+u9CtcSro+pRERUMBgoKYdPP/0U8+bNQ0JCgrVboSLMIBvQf11//Hbmt2e6dPtf2TNwS3oswaD6gyzuKTo62hwgd+3ahfT0dFSoUAFdu3ZFSEgI2rRpA0dHR4vHUZuiKIi+F40bKTegQEFJ+5Ko6lFVk/0riYjyi4GScli5ciX69++Pe/fuwc3NzdrtUBE1dstYzD4yO99h8r8ECNjSfws6Ven0TF+XmZmJ/fv3Y/Pmzdi0aRPOnTsHnU6HVq1amWchq1evnmvVNRERPTsGSsohPDwcwcHBOHLkCBo2bGjtdqgI2nl5J5775TnV6omCiNKOpXFuzDm427s/8bWxsbHYsmULNm/ejO3btyMlJQVlypRBSEgIunbtivbt2+fYaJyIiNTBQEk53L9/H25ubli+fDn69+9v7XaoiMkyZqHSjEqIS4577GKS/JAECW8EvYE5XefkeNxgMODw4cPmWcjjx49DFEU0bdrUPAtZr149zkISEWmMN+FQDq6urihTpgy3DqJ8+SPqD1y/f131ukbFiMXHFmNK+ynISs7C1q1bsXnzZvz999+4e/cuPD090blzZ/zvf/9Dx44d4eHhoXoPRET0eAyUZKYoCm7cuAEvLy9s2bIFaWlpuHTpEiZOnIhmzZpZuz0qAmYfnW3e+kdtmcZM1B9UH1d/uwpFURAUFISxY8ciJCQEwcHBkCRJ9TGJiChvGCgJAHDq1Cm0aNECSUlJ5seOHTsGo9GI559/noGSnirDkIH9V/drEiazZfplYvHixejcuTN8fHi0IBFRYcFASQAAb2/vXPeZGY1GiKKI559/3kpdUVFy6uapJ25abikFCuQyMgYPHqzZGERElD+itRugwqF06dJYunRpjsdEUUSrVq3g6elpnaaoSLmQeEHzMW6k3sCDrAeaj0NERM+GgZLMevTogaFDh0IUTX8tZFlGnz59rNwVFRUZhowCGSfTmFkg4xARUd4xUFIO33//PcqVK2f+/IUXXrBiN1SU2OvsbWocIiLKOwZKysHZ2Rlr1qwBAPj6+nLhA+VZdc/qmo/h6+LLQElEVAhxUQ7l0rBRQ4z9bCyEMgLmHJ0DAQK8nb3RoEwD+Lv5c5NoeqSapWtCL+qRJWdpUl8URDQu21iT2kREZBkGSjKLTIjEnKNzsPLkSqQqqUAcIMSZwmP2mcylHEphSP0hGBE8ApVLVbZmu1TI6CU92lVshx2Xd2iydZCiKOhU+dnO8yYiooLBoxcJt1JvYdTmUVh7Zi10ou6pW79IggRZkTG20VhMaT8FTnZOBdQpFXYbz2/E86u02WbKUe+IGxNvwNnOWZP6RESUf7yHspjbFb0L1WZVw4azGwAgT/sIGhUjFCiYdXQWas2phVM3T2ndJhURXap0QZVSVSAJ6p5aIwoiRgWPYpgkIiqkOENZjG29uBXPr3oesiJDVuR81ZAECU52TvjntX9Q17uuyh1SUXTw2kE0X9zcfJuEpSRBgp+rH06POs3ZcCKiQoozlMXUudvn0HN1T8hy/sMkYJqtTM1MxXM/P4fEtEQVO6Siqmm5pvig5Qeq1BIgQBAELH9xOcMkEVEhxkBZDBllI17d8CqMshEy8h8mzfUUIxLTEjFuyzgVuiNb8HnbzzE8aLhFNURBhCRK+PWlX9GifAuVOiMiIi0wUBZDSyKX4GjcURgU9c5dNipGrDi5Antj9qpWk4ouQRAwt+tcfNX+K+hEHXTis20oIQkSvJy8sG3ANrxQg5vrExEVdgyUxYyiKPj+0PcQoP5ekjpRhxmHZ6hel4omQRDwbot3cWz4MTTybQQATw2WoiBCJ+rweoPXcW70ObSt2LYgWiUiIgtxUU4xcyT2CBov1G5zaFEQEf92PLycvDQbg4qe7du3Y+rPU1H15arYGb0TFxMv5rh3115nj7reddGjWg8MbTCUf3+IiIoYbmxezPxz5R+IgmjRQpwnkRUZh64fQvdq3TWpT0XPrl27EBISAoPBgHWz18G1qytSM1NxNekqsuQsOOmdUMG9AiRR3a2GiIio4PCSdzETFh+myeXubDpRh/C4cM3qU9GyatUqdOzYEQaD6X7dW7duAQCc7JxQo3QN1PWui8qlKjNMEhEVcQyUxczlu5c1ORbvv64kXdG0PhV+iqJg+vTpeOWVV2A0/vv3LTtQEhGRbWGgLGayjFma1lcUBVmytmNQ4ffuu+9i0qRJuR6/efOmFbohIiKtMVAWMy4lXDStLwgCXOy0HYMKN0VRsGPHDgCAJOW8lM1ASURkmxgoi5l63vWgF/Wa1TfKRtT2qq1ZfSr8BEHAkSNHsHnzZvj5+QEARNH0o4aXvImIbBNXeRczwb7Bml6SVqAgqEyQZvWpaJAkCS1btkRiYiLGjx+P0qVLY9myZShXrpy1WyMiIg1wH8pi5kbKDfh97weDrN4pOf/l6eiJuLfioJe0mwWlomHRokUYNmwYoqOj4e/vb+12iIhIQ7zkXcx4O3vjpRovPfNReHkhCiJGBY9imCQAwE8//YTOnTszTBIRFQMMlMXQ/1r8T5ONzUWDiM6enVWvS0VPZGQkjhw5guHDh1u7FSIiKgAMlMVQfZ/6eK/Fe6pvcO4e6o52jdph2rRp5o2sqXhasGABypQpg65du1q7FSIiKgAMlMXUR60+QqOyjSAJlp9QIgoiXq71MqJ/j8aoUaPw7rvvolGjRjh27JgKnVJRk5qaiuXLl+P111+HTsd1f0RExQEX5RRjd9PuouMvHXEs4Vi+T88RIKB7te74tfevsJPsAABHjx7F0KFDcfr0abz99tv49NNP4eDgoGbrZEV30+7icOxhhMWFIfputPk87pqlayLYNxintp/C8KHDcfnyZVSoUMHa7RIRUQFgoCzmUjJTMHHbRMwPnw9REPN8b2X2zOZHrT7CB60+yLXIJysrC9OmTcPnn38OPz8/LFiwAG3btlW9fyo4R2KPYMbhGVhzeg0MsgGSIEEQBCiKAlEQYZANUKBAl6WD/w1/7PtuH3xdfK3dNhERFQAGSgIA7Ly8E+/ufBdhcWHQibpHbiskQIAoiDAqRjxX6TlM7zAd9XzqPbFuVFQU3njjDezbtw+vv/46pk2bhpIlS2r1bZAG7mfcx8RtE7EgYsFj/248TBRE2Ovs8UOnHzC0wVAIgrr36xIRUeHCQEk5RMRHYNXJVTgcexjHEo4hJTMFAOBu746Gvg3R1K8pBtYbiCqlquS5pizLWLhwISZNmgRHR0fMmjULL774IkNGEXDhzgW0/7k9YpNj870zQI9qPbD6pdWw19mr3B0RERUWDJT0RNkhQhQsX78VGxuL0aNH448//kDPnj0xa9YslC1b1uK6pI1LiZfQdFFTJKYl5vseW8D0d+e5is/hr1f+Mt9nS0REtoWrvOmJREFUJUwCQNmyZbFhwwasXbsWhw4dQs2aNTF//nzIsvp7YpJlMo2Z6L66u8VhEjC9KdkRvQMf7vpQpe6IiKiwYaCkAiUIAnr16oUzZ86gd+/eGDFiBNq2bYuoqChrt0b/8cW+L3D21lmLw2Q2WZExPXQ6Dl0/pEo9IiIqXBgoySpKliyJhQsXYufOnYiNjUW9evUwZcoUZGVlWbu1Yi8hJQFf7f8KCtS9G0YUREzYOkHVmkREVDgwUJJVtWvXDidPnsSECRPw8ccfIzg4GEePHrV2W8XaoohFmhzNaVSMOBx7GMcTjqtem4iIrIuBkqzOwcEBX3/9NY4cOQJJktCkSRO8/fbbSE1NtXZrxdKCiAWaBEoA0Ik6LDu+TJPaRERkPQyUVGg0aNAAR44cwddff405c+agdu3a2LZtm7XbKlbuPLiDK0lXNKtvkA04cO2AZvWJiMg6GCipUNHpdJg0aRJOnjyJSpUqoVOnThg0aBDu3Llj7daKhWMJ2p+/fjzhOIyyOot9iIiocGCgpEKpSpUq2LFjBxYtWoQ///wTNWrUwKpVq8BtU7V1I+WG5mNkGDOQmsXbGYiIbAkDJRVagiBgyJAhOHv2LNq0aYNXXnkFzz//PK5evWrt1myW2iu7H0erezSJiMg6GCip0PPx8cGvv/6K33//HceOHUOtWrUwa9YsboiugZL22p+zLgkSnPROmo9DREQFh4GSiowePXrgzJkzGDhwIMaOHYsWLVrgzJkz1m7LptT3qa/5GDVK14Be0ms+DhERFRwGSipS3NzcMGfOHOzbtw+JiYmoX78+PvvsM2RkZFi7NZvg6+KL0o6lNauvE3Vo6tdUs/pERGQdDJRUJLVs2RKRkZH43//+hy+++AINGjTAwYMHrd1WkScIAgbWHQhJkDSpb5ANeKXOKwAARVGQkZGBpKQk3LhxA1evXuVtDERERRQDJRVZ9vb2mDx5MiIiIuDs7IzmzZtj3LhxSE5OtnZrRdqI4BGqneH9XwIEVC1VFT0De0KSJEiSBHt7e7i7u8PHxwf+/v6YNm2a6uMSEZH2GCipyKtTpw5CQ0Px3XffYdGiRahduza2bNli7baKrKoeVTG4/mDVZykVKPj6ua9Rr249yLL8yC2gWrZsqeqYRERUMBgoySZIkoQJEybg1KlTqF69OkJCQtC/f3/cunXL2q0VSd93+h6ejp4QBXV+REiChL61+uLFGi/i77//RmBgIEQxZ+2qVauicePGqoxHREQFi4GSbErFihWxdetW/Pzzz9i6dStq1KiB5cuXc0P0Z+Ru7471fddDL+otDpU6UYeqHlUxt+tcAKZbFf766y+ULFkyR6i8cOECqlWrhnnz5iEtLc2iMYmIqGAxUJLNEQQBAwcOxNmzZ9GxY0cMHDgQXbp0QUxMjLVbK1KalWuGrQO2ooRUAjpBl68aoiCimkc17Bm0ByUd/t3jsmzZsvj9998hCAIA08lIhw4dQoMGDTB69Gj4+/tj8uTJPHKTiKiIYKAkm+Xl5YWVK1di48aNOHPmDGrVqoUffvgBRiPPkc6rNhXa4MTIE2jk1wgAIObxR4ZO1EGAgLGNxuLIsCPwdvbO9ZoWLVpg1qxZAID33nsPjRs3xq+//orz58+jd+/emDJlCsqXL4/x48fzzQARUSEnKLwWSMVAcnIy3n//fcyePRsNGzbEwoULUadOHWu3VWTIioyfj/+Mbw9+i1M3T0EURAgQcqwG14t6ZMlZECCge7Xu+F/z/6FpuSfvOakoCs6cOYOaNWuaZyuz3bp1C7NmzcKsWbOQlJSEPn36YNKkSQgMDNTkeyQiovxjoKRiJTQ0FEOHDsWFCxfw7rvv4oMPPoC9vb212yoyFEVBWFwY9l3Zh/D4cJy/cx6Zxky42LmgrnddBPkGoVPlTijnVk61MVNTU7FkyRJ8++23iImJQYcOHfDOO++gffv2uUIoERFZBwMlFTsZGRn4+uuv8eWXX6Jy5cpYsGABWrRoYe226CkMBgPWrl2LqVOn4tixYwgMDMSkSZPQu3dv6HT5u8eTiIjUwXsoqdgpUaIEPvnkExw7dgzu7u5o2bIlRo0ahfv371u7NXoCnU6Hl19+GeHh4di+fTs8PT3xyiuvoGrVqpg5cyZSU1M1G1tWZFxKvISjsUcRFheGa0nXuHMAEdF/cIaSijWj0Yi5c+fivffeM58T3r17d2u3RXkUGRmJadOmYc2aNXBzc8OYMWMwZswYlC5t+XnkqZmpWHlyJZafXI7wuHCkZuUMrO727mjq1xSv1X8NPav3hF7SWzwmUUGLS47DhrMbEBYfhqOxR5GUngRBEODn6oeGvg3RxK8JelTvAUe9o7VbpUKOgZIIwNWrVzFy5Ehs3rwZffr0wYwZM+DtnXtlMhVOMTEx+P7777Fw4ULIsozXXnsNb7/9NipXrvzMtYyyEd8f+h6f7vkUqVmpECBAwaN/TEqCBKNiRGnH0viu03foX6c/7+u0gKIouJh4EWFxYThz6wxSs1KhF/WoWLIign2DUcerDkroSli7TZtwPOE4Ju+bjA3nNkBRFEiiBINsyPGa7IV2rnauGNpgKN5v+T48HD2s1DEVdgyURP9PURSsXr0a48aNg9FoxLfffovBgwfnCAjnz59H1apVGRoKqTt37mDu3LmYMWMG7ty5g169emHSpElo2LBhnr4++m40+q7ti6NxR59p3OzQ+XzA81jWc1mOPTfp6e6l38PSyKWYeWQmLt+9DMAUZrIZZAMUKHCxc8HQBkMxMngkqnpUtVa7RVqWMQtT/pmCyfsmA0COnRqeRBIkuNu7Y1H3RehRvYeWLVIRxUBJ9JDbt2/j7bffxs8//4z27dtj/vz5qFy5Mn7//Xe88MIL+O677/Dmm28+tU7s/Vgcun4IEfERiE2OhVExwq2EG+p610WwbzDq+9RX7WhDyiktLQ3Lli3Dt99+i4sXL6Jt27Z455130KlTp8e+GYi6HYWWS1ribvrdXDM1eSUJEgI8ArDvtX3wdPS05FsoNtadWYdhfw3DvfR7APDY2eBskiBBgYL3W7yPj1p/BDvJrgC6tA2pmanosboHdkXveurv86OIECFDxudtPsdHrT/SoEMqyhgoiR7j77//xvDhw3Hz5k289957mDlzJm7dugVHR0dcunQJPj4+ub5GURRsurAJMw/PxLbL2wCYNvnO/t9MFERkyVkAAH83f4xtNBZDGwyFm71bwX1jxYjRaMTvv/+Ob775BkePHkWdOnUwadIkvPzyy9Dr/50Bu/PgDurMrYNbD27lO0xmkwQJ9bzr4eDQgww7T2CQDRj+13Asjlz8xNsKHkeAgFpetfD3gL/h6+KrUZe2I8uYhZAVIdgVswuyIltc75vnvsE7zd9RoTOyFQyURE+QkpKCjz/+GN9//735MUmS0K9fP/zyyy85Xht7PxZD/xyKrZe2mu+texpREFHasTQW91iMkKohqvdPJoqiYN++fZg6dSo2b96McuXK4c0338TQoUPh4uKCfmv74bczv+X58t/TCBDwceuP8WmbT1WpZ2uMshGvrHsFv535LV8zZdl0og5+rn44+PpB+DjnfoNH/5q8dzI+2fOJRb/f/yVAwIEhB556eAEVHwyURE+xb98+tG7dOtfj//zzj3n/yj0xe/D8queRbkh/5hkuURAhKzLebvo2pnWYxvszNXby5ElMnz4dK1euhLOzMzqO7ohf9b+qPo4kSDg16hSqe1ZXvXZR9/nez/Hpnk9VCTc6UYdg32Dsf20/JFFSoTvbc/LGSTT4qYHFs+//JQkSKrhXwKlRp2Cv4+EQxH0oiZ4oe8XwowwcOBBGoxH7ruxDp+Wd8CDrQb5+YGdffvr24LcYt3Uc9zfUWJ06dbBs2TJcvnwZr7/+OtbGr4WgqB/iBUHAzMMzVa9b1B1POI7P936u2kyZQTbg0PVDmHF4hir1bFH2Ahw1GRUjLt29hNWnVqtem4omzlASPUFWVhZ69OiByMhI3Lx5E0Zjzkuikz6dhAX2C3A/474q9yUBwJIeSzC4/mBVatGTnb9zHtVmVdOsvoPOATcn3YSznbNmYxQ1bZa2wf6r+1W7vSCbvc4ecW/FcYX9Q+KT41Hu+3Kq/34Dpqsr9bzrIWJ4hOq1qejhDCXRE+j1emzevBlxcXHIzMxEfHw8wsLCsH79eowdNxbH/I4hOSNZtTApQMDYLWMRez9WlXr0ZDsv74QA7W4xSDOk4UjskVyPp6enY8GCBVi7dq1mYxdGZ2+dxd4rezUJNxmGDCyNXKp63aLuj6g/VPv59DBZkXEs4Rii70ZrUp+KFgZKojwSRRE+Pj4ICgrCCy+8gN5v9caO6ztU/cdRgYJ0Qzo+2/uZajXp8cLjwzW9704URITFhZk/T0lJwbfffovy5cvjjTfewOeff67Z2IXRksgl0Inanbv+U/hPj3z81q1bmDZtGq5du6bZ2IVVWFyY5veWhseHa1qfigYGSqJ8mn10tib/OBpkA345/ot5Xz7SzplbZ1RdqPAwURARdTsKiYmJ+Oyzz1C2bFlMmjQJt27dAoAcWxcVB/uv7tfs91uBgnN3zuF+xn3zY/fu3cNHH30Ef39/vPPOO1i3bp0mYxdm4XHhmv4d14k6HE84rll9Kjq0e6tIZMNSMlOw7uw6zX5QZxgzsPbMWgxtMFST+mSSZkjTtL6iKEi8n4jSpUtDlnNfdjxz5gzq1q0LvV4PvV4PnU6X6+NHPWbp82rUEcVnm4/IvjyqtWPxxxDkGYQZM2bg66+/RmpqKmRZhiiKMBie/f9XRVEgyzIMBgOMRiMMBkOOjx/1WGF6/nzV84CG26EKEPjmlwAwUBLly7H4Y5q+65dECUdijzBQasxB56BpfUEQ4O7ijpCQEGzZsgWyLOdYxe/h4YE2bdogKysLBoMBWVlZuT5+8ODBE5/P/vhxzz8qyKpBFMVnCquCg4D09uma9PJf67atQ4cxHZCVlZXjcVmW8d1332Hp0qXPFM4eXohXEHQ6HXQ6HSRJeuLHeXlekbVfd8vtmghgoCTKl4j4CPP+kVowyAYcvn5Yk9r0rxqeNXA07qh2l2EVBTVK18A7f72D+Ph4fPnll5g/fz4AwGAwoHr16pgxQ9vtbrJn154WPp8WWC19bYoxBUfxbGek54fOzhRiHw6UgiDA398fTZo0eaZAlt/n//v5s3z9s878Pk3rpa2x78o+VWv+l6zIKONcBoDp7/v58+cRGhqK0NBQ7Nu3Dx06dMCsWbM0G58KDwZKony4kXoDkiBpFiizxyBtBfkGYUnkEs3qGxUjgsoEAQDKlCmDWbNmYeLEifjss8+wbNkyuLlpf+SmKIqws7ODnZ11j4HMNGZizZdrNP1/BgDaNWuHqUlTsXr1anz++ee4cOGCOaR17twZn3zyiabjFzYNfRvi4LWD5iNf1WZUjEg4loCAIQGIi4tDamoqANMsq8FgQKNGjTQZlwofLsohyoeC2L5V6394CWhfsb1qG2w/ioPOAY39Gud4rEKFCliyZAkuXryImTOLz8bndpIdqpSqovk49bzrQafTYcCAATh37hzWrl2LmjVrQpZl6HTFbw6lqV9TzcIkYDox59bxW7hw4YI5TAIw36/atCmPZiwuGCiJ8qGUQynNA5+QLmDnzp24efOmpuMUZ9U8q6G1f2tIgvr3gOlEHQbXH/zYTc0rVaoEX19f1cctzJr6NdV026BSDqXg5+pn/lwURfTq1QsnTpzAgQMHMHLkSM3GLqy6BXRDSXttNnvXiTr0qtELyxcux8yZMx95bOyECRPQsmVLfPTRR9ixYwcePHigSS9kfQyURPlQ36e+JpszZxMh4vaJ23juuefg7e0NHx8fdOjQAW+//TaWLVuGiIgIpKdrv8ChOJjUbJImf5ayImNso7Gq1y3K+tTqo9n9qjpRh1dqv/LIUCMIApo1a4ZSpUppMnZhVkJXAiOCR2jypskgGzC60WgAwJgxY7B582Y4OjpCkkxjlSpVCtOnT4e3tzfmzZuHDh06wN3dHc2bN8cHH3yAbdu2ISUlRfW+yDp49CJRPiSmJcJjqodm9UVBxLcdvkWXUl1w4sQJnDx50vzfy5cvm14jiggICEDdunVRp04d83/9/f1Vv7Hf1vX9rS/WnV2nWrAUIODDVh/i87bFa+PypzHKRlT8sSKu37+uya0Gp0edRs3SNVWvW9TdS7+H6rOq49aDW6pdWZEECT2q98C6Pjn39jx58iQ6d+6MuLg49OvXDytXrgRgWhx29uxZ7NmzB3v37sXevXtx8+ZN6HQ6BAcHo3Xr1mjTpg2aN28OFxcXVXrUgqzI2BOzBzsv78SRuCOIuh2FDGMGSkglUNurNoJ9g9Gpcic0K9fskW9ubBkDJVE+dfylI3ZF79JkdksSJFx98yp8XXJfEk1OTsbp06dzBM0TJ07g3r17AAAXFxfUrl07V9B0d3dXvU9bcfvBbdSZWwe3Um9Z/OcpCRLqeNfB4aGHYSdZdyFMYbQ0cile++M1VWtKgoQXa7yIX3v/qmpdW7L14lZ0WdFFlVqSIMG1hCvOjTkHLyevXM8nJCRg1KhRGDNmDNq1a/fIGoqi4Ny5c9i7d685ZCYkJECSJAQFBaF169Zo3bo1WrRoUSCL157GKBvxU/hPmH5wOi7fvQydqINRNuZ4YyRAgCRKMMgG1PCsgXdbvIuBdQcWm2DJQEmUT39G/Ykeq3uoXlcn6tCjWg+s7ZP3c54VRUFsbGyu2cyzZ8+ab44vV65cjoBZt25dVKtWrdid1vI4526fQ8slLXEv7R4MSv4uy0qChCqlquCf1/5BaafSKndoGxRFQZcVXbAzeqcql78FCHC3d0fUmCib+D2XFRkHrh7AwesHEREfgWv3r0FWZJRyKIVAn0AE+wajQ6UOcLJzeuba0w5Mwzs73rGoP0mQoJf02PXqLjQtp96CG0VRcOHCBXO43LNnD+Li4iCKIgIDA9GmTRu0bt0aLVu2LPA3x+fvnMerG17F4djDECDkaXY9+3XPVXwOi3osQnm38gXQqXUxUBLlk1E2otmiZohIiFD1vjCdqEPEGxGo413H4lqZmZmIiorKFTSvX78OwHT0X40aNXLNZvr6+habd9X/dfnuZfT+rTeOxR97pkuy2f94hFQJwc8v/AwPR+1uh7AF8cnxaLSwERKSE/Id3oF/Z4Q2vbIJHSt3VLHDgpduSMfco3Mx48gMxNyLMd/zmD1j/t/ZL2c7Z7we+Drebvo2yrmVe6Zxfjz0I97a9hYECM88G589M7nplU2qhslHURQFly5dyhEwr1+/DkEQUL9+ffMl8pYtW2p6b+y+K/vQZUUXZBoz8/VzXifq4GLngh2v7kCDMg006LDwYKAkskDU7SjUnVcXmcZMVeoJEDC57WR80OoDVeo9zt27d3MEzBMnTuDUqVPmG+RLlSqVazazVq1acHZ+9IplW2KQDfg29FtM3jcZD7JMK1IfFy4lQYJRMcLDwQPfdfquWF3eslT03Wi0WdYGsfdj83WbgSRIEAURa/usRfdq3dVvsAAdun4IAzcMxKXES3l+I6MTdbCT7PBj5x/xeuDrz/T3LiwuDAM3DMS52+fydECDTtTBIBvQu2ZvzA6ZbZWZYEVREB0dneMS+ZUrVyAIAurWrWsOmK1atYKHhzpv6I7GHkWrpa2Qacy06N5TSZDgbOeMQ0MPobpndVV6K4wYKIkstPzEcgzcMNDiOqIgonPlzvij3x+abq3yOLIsIyYmJlfQvHDhgvn4vsqVK+cKmpUrVzav6rQlKZkpWHlyJX4+/jMi4iNynfvtWsIVTf2aYkjgEPSs3pP3S+bDnQd3MGbLGKw+tfqZTp4SIKBm6Zr45YVfEFgmUOMutbUoYhGG/TUMoiDm+/7d/nX6Y0mPJdBLeb99JdOYibVn1mLm4Zk4FHsIgCk4CjAFU6NihKzI0Ik6vFTjJYxuNBotyrfIV39aiYmJMS/w2bNnD6KjowEAderUMd+D2bp1a5Qu/ewBODUzFbXm1ML1+9dVuU9eEiTULF0T4W+EP9OfU1HCQEmkgqWRSzHkjyEW/aPQtWpXrO2zFvY6e5W7s0xaWhrOnDmTK2hm74/p4OCAWrVq5Qqa+fkhXljJioyLiRdxN+0uBEGAl5MX/N38ORupko3nN2LKP1Nw8PpBSIIEBUqOcClAgE7UIUvOQlmXsnizyZsY23hskQ/xai1QEiDg5dovY/mLyyEKz77DQ+z9WITHhyMyIRL30u9BEiT4OPsgyDcIDco0gGsJV4t7LAhXr17NETAvXboEAKhZs6b5HszWrVvD29v7qbUmbJ2AmUdmqrrfsAABn7f9HB+2+lC1moUJAyWRSvJ72UoURHzV/iuMbzweklh0Zvpu3LiBkydP5giap0+fNu+P6ePjkytk1qhRA/b2hSswU+Fx4sYJbL6wGWFxYTiecBypWanQS3pULVUVDX0bonWF1uhQqUOR+v/kcU7dPIXA+YGq3n89q8ss876QBMTGxua4RH7+/HkAQPXq1c2XyFu3bo0yZcrk+LqElASU+76cJnumOumdkDAx4bEHHhRlDJREKko3pGP2kdmYcWQGriZdfeRsi17UI0vOgr1kjwH1BuCdZu+gqkdVK3atHqPRiIsXLz5270xJkhAQEJAraPr7c7aPig+DbECjBY1w8sZJixYlPcxeZ4/To06jUslKqtW0JXFxcdi3b585YJ47dw4AEBAQkCNgLr20FB/v+ViT09AECJjXbR7eCHpD9drWxkBJpAFZkbE3Zi8OXj+Io3FHcS3pGoyKESXtSyLQJxBBvkEIqRoCd3t3a7daIB61d+bJkydx9+5dAKa9M+vUqZMjaBbnvTNTMlMQmRCJq0lXzat6a3vVRpVSVfJ1SZMKl99O/4Y+a/uoXlcn6jCw7kAs7rFY9dq2JDMzE9euXYOTkxP27dtnnsU8c+YMAMBuvB0yS6qz0PJhAgS0qdAGuwbt0qS+NTFQEpFVPLx3ZnbQPHfuHLKysgAA5cuXzzWbGRAQYJN7Z6ZkpmDFiRWYGzYXJ26ceORtE056J/Ss3hOjG45GE78mnNUtolotaYXQa6GaHIpQQiqB+LfjUdJBm/O7bcEvv/yCV199FS1atMCHH36Ijh07QhAE3Lx5Ezv27MCAMwOgCNpFIxc7FyS9m2Rz//8yUBJRoZK9d+Z/TwH6796ZdnZ2qFGjRq6gWaZMmSL5A1pRFCyNXIrxW8cjJdO0bdOT7sHN3sKllX8rLOmxhJc3i5i45DiU/a6sZvUFCFjUfRFeC1T3NCJb8tNPP2H48OGQJAlGoxF169bFxx9/jBdeeAHHbxxHg5+03y/yyoQrNrfZOQMlERUJedk78+EN2mvXrg0np2c/UaSgJKUnod+6fthyccszf61O0EEn6TC/23y8Wu9VDbqj/Dp27BiysrLQqFGjXM/9ce4P9FzTU7Ox9aIeQxsMxZyuczQboyAoigKj0YjMzExkZWWZfz38+aMee9rnoaGhWLfu3zPIBUGAoihwdXXFmG/HYErsFM2/vxMjTqhyeEVhUvCb3RER5UPJkiXRqlUrtGrVyvzYo/bO3LZtG2bPng1ZliEIAipVqpQraBaGvTOT0pPQdllbnLhxIl9fb1AMMBgMGPT7IKRkpmBUw1Eqd0j5NWzYMISHh6NBgwZ466230Lt3b9jZmbY4ikyINM8yayFLzsKR2CPPHMIseUyrr1OTKIrQ6/Wws7Mz76ubLXte7f79+7h25VqBJCNb2KngYZyhJCKbk5e9M2vXrp3rsrmnp2eB9KcoCjr80gF7Yvaodh/dxn4b0TWgqyq1yDItW7bE/v37IYoiZFmGp6cnxowZg+HDh2PKsSmYFzYPWbK6gSmHewB+UK+cJEnQ6/XmQJb9sRaPaVVLFP9dzLZmzRq8/PLLAACdTgej0YjBgwfjk08+QZZLFqrO1H7XjcR3Em3uPlcGSiIqNrL3zvxvyDxz5kyOvTMfns3Mz96Zx48fhyRJqF279iOfnx82HyM2jbD4+8kmCiI8HDwQNSbK5v6RKiwURUFqaiqSkpKQlJSE+/fvP/bjdevWme/5fdhLC1/CH3F/aBooPSVPTC83XZVAptPpcoQxW7B+/Xr06tULANCrVy988cUXqF7ddCSioihw/drVfD+zFsq5lsPVN69qVt9aGCiJqFgzGAy4ePFirqCZfYxb9t6ZDwfNJ+2dWaNGDVy8eBHTp0/HuHHjcrzubtpd+H3nhweGB6p+H5IgYWTwSMwMmalqXVtgMBhyhL6nBcLHffzwpdL/cnFxgZubG9zc3HDjxg3cvn3b/Fz2n3+bNm3Q6sNW+GL/F5qs8M7WpGwTHBx6ULP6Rd2tW7fw2Wef4bXXXkNQUFCu5zv80gG7o3dr8mekE3ToW7svlr+4XPXa1sZASUT0CMnJyTh16lSuoHnv3j0AgKurK2rXrp0raDo4OMDR0RFGo+kfo+effx5Lly5FqVKlAADfH/web297O8+nKT0LB50DEiYmFJmj8p5GURSkpaU9MejlJRA+ePD48K7T6cxB0M3NDa6uro/9/HEfOzs757gnd8yYMZg3bx4URYEsy2jfvj1+/PFH1KpVC5svbEbXldrdmqAX9RgZPBI/dvlRszFs3a+nf0XftX01q7/r1V1oW7GtZvWthYtyiIgewcXFBU2bNkXTpk3Njz28d+aJEydw4MABLFy4EAaDaZGFj4+POUwCwKZNm1C7dm2sX78eTZo0weyjszXrOd2QjlUnV2F48HDNxsgro9GI5OTkZ5oFfNRz2b+vj+Lk5PTIEFi+fPk8B0J7e3vVt5tyd3eH0WhExYoVMWPGDHTt2tU8RkPfhhAgaPKGAjAtymlUNvfqcsq7ntV7orRjadx+cFvVPydREFG5ZGW0qdBGtZqFCWcoiYgslL135okTJ7Bq1Sps2rTpka+b9OkkTMM0zfqQBAl9a/fFihdXWFQnPT093wEw++Ps7ZweRRTFZ54FfPhzFxcX6HSFc07k6tWr2Lt3L/r27Wte3f1fXZZ3wfbL2zW5pGrLZ0UXJK1OM9r56k60q9hO9bqFQeH8v5GIqAixs7MzHxd54sQJbNmyBbIsm1f5AqZtj+473we0u9cfRsWI0KuhuH79ukVhMDPz8cfOOTg4PDL0+fr65vlysaOjY5HchD6vypcvj4EDBz72+TGNxmDrpa2qjysJEoYEDmGYVEHvWr3R63Qv/H7ud1WCvyiIGNZgmM2GSYCBkohIVRcuXIAsy7Czs0P79u3RvXt3dO3aFeXKlcPsI7MhbNHucicAxCTGoFy5crkeFwQBrq6uuUKet7c3AgIC8jRT6Orq+sgZN3o2IVVD0KZCG+y/sh8GRZ39KAUIcLZzxvst31elHgFLeixB9N1oHL9x3KJQKQoiWvm3wg+df1CvuUKIl7yJiFR0+vRpXLlyBW3atIGjo2OO53449APe3vY2ZOXxq4XVsKnhJri7u+cIg87Ozja3/UtRFnMvBjVn10S6IV21NxgrXlyBV+q8okotMklKT0LPNT2xJ2ZPvmv0qNYDq3qtgoPeQb3GCiEGSiKiArIgfAHe2PiGpmPY6+yR9kGapmOQOjad34Qeq3tAVmSLQ+WbTd7Etx2/telbCaxFVmTMOjIL72x/B1lyVp7eEIqCCEe9I2Z2mYlB9QYViz8Xvl0lIiogtbxqaT5GzdI1NR+D1NE1oCs29N0AO8kOOvHZ70ATBdM/4e80e4dhUkOiIGJc43G4PP4yPmr1EUo7ljY/pxf15l/ZyrqUxZftvsTlcZcxuP7gYvPnwhlKIqIC8iDrAVy+ctHskrdO1GFYg2GY03WOJvVJGxfuXMCg3wfh4PWDEAUxzzNgno6eWNJjCUKqhhRAl5TNKBtx7vY5hMWF4ULiBWQYMmCvs0d1z+oI8g1CgEeAOewXJwyUREQFqN2ydth3ZZ9mJ6XwTO+iSVZk/Hb6N8w8MhMHrh0AYJr9yv57IgkSDLIBChSUcy2HsY3GYljQMLjbu1uxa6J/MVASERWgDWc34MVfX9SkdjnXcogeHw1JlJ7+Yiq0LiZexOHrhxEWF4YbqTdgVIxwK+GG+j71EewbjGDf4GI5A0aFGwMlEVEBMsgG1JxdE5fvXlZ9lnJOyByMbDhS1ZpERHnBtzhERAVIJ+qw/MXlqt5HqRN1aFG+RaE4cpGIiicGSiKiAtaobCN83vZzVWpJggQXOxcs67mMl0GJyGr404eIyAo+aPkBJjadaFENnaCDawlX7Bq0C5VKVlKpMyKiZ8d7KImIrERRFCyIWIAJWycgy5j1zMfwNS7bGMtfXI4qpapo1CERUd4wUBIRWVnMvRi89fdb+P3c7+Z9CB91cookSDAqRpR2LI33W76PsY3GckU3ERUKDJRERIXEtaRrWBK5BPuu7MPRuKO4n3EfACBAQKWSldDErwl6VOuBntV7Qi/pn1KNiKjgMFASERVCiqIgNSsVBtkAR70j7CQ7a7dERPRYDJREREREZBGu8iYiIiIiizBQEhEREZFFGCiJiIiIyCIMlERERERkEQZKIiIiIrIIAyURERERWYSBkoiIiIgswkBJRERERBZhoCQiIiIiizBQEhEREZFFGCiJiIiIyCIMlERERERkEQZKIiIiIrIIAyURERERWYSBkoiIiIgswkBJRERERBZhoCQiIiIiizBQEhEREZFFGCiJiIiIyCIMlERERERkEQZKIiIiIrIIAyURERERWYSBkoiIiIgswkBJRERERBZhoCQiIiIiizBQEhEREZFFGCiJiIiIyCIMlERERERkEQZKIiIiIrIIAyURERERWYSBkoiIiIgswkBJRERERBZhoCQiIiIiizBQEhEREZFFGCiJiIiIyCIMlERERERkEQZKIiIiIrLI/wEeOz0mH98wPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G0 = draw_digraph(session_0_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code found at https://towardsdatascience.com/build-a-super-simple-gan-in-pytorch-54ba349920e4\n",
    "\n",
    "Very basic task: Training a GAN to generate positive integers using vectors of their binary encodings (Ex: 56 is 0111000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def create_binary_list_from_int(number: int) -> List[int]:\n",
    "    if number < 0 or type(number) is not int:\n",
    "        raise ValueError(\"Only Positive integers are allowed\")\n",
    "\n",
    "    return [int(x) for x in list(bin(number))[2:]]\n",
    "\n",
    "def generate_even_data(max_int: int, batch_size: int=16) -> Tuple[List[int], List[List[int]]]:\n",
    "    # Get the number of binary places needed to represent the maximum number\n",
    "    max_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Sample batch_size number of integers in range 0-max_int\n",
    "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
    "\n",
    "    # create a list of labels all ones because all numbers are even\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    # Generate a list of binary numbers for training.\n",
    "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
    "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
    "\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Generator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense = nn.Linear(int(input_length), 1);\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 201):\n",
    "    input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Models\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    # Optimizers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "    # loss\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Create noisy input for generator\n",
    "        # Need float type instead of int\n",
    "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "        \n",
    "        # Generate examples of even real data\n",
    "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
    "        true_labels = torch.tensor(true_labels).unsqueeze(1).float()\n",
    "        true_data = torch.tensor(true_data).float()\n",
    "\n",
    "        # Train the generator\n",
    "        # We invert the labels here and don't train the discriminator because we want the generator\n",
    "        # to make things the discriminator classifies as true.\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        # Print generator's loss at every 50th step\n",
    "        if (i % 50)==0 :\n",
    "          print(\"STEP \", str(i))\n",
    "          print(generator_loss)\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        z = torch.zeros(batch_size).unsqueeze(1)\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, z)\n",
    "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP  0\n",
      "tensor(0.6235, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  50\n",
      "tensor(0.6417, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  100\n",
      "tensor(0.6620, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  150\n",
      "tensor(0.6862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  200\n",
      "tensor(0.7052, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So essentially what we'd do for the graphs is, instead of feeding integers, we would feed session data. Feature vectors would represent [div_1, div_2, ..., div_n] with each element denoting whether or not an element was clicked at that segment of the session (vertex of the graph). Only problem is, human-made session data is not so easily generated as it is with random numbers in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary so far:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I've read:\n",
    "* (GAN theory) https://www.frontiersin.org/articles/10.3389/fdata.2019.00003/full\n",
    "* (undirected graphs GAN with tensorflow) https://github.com/hwwang55/GraphGAN (further documentation: https://arxiv.org/pdf/1711.08267.pdf)\n",
    "* (directed graphs GAN with pytorch) https://github.com/THUDM/GraphSGAN (further documentation: https://arxiv.org/pdf/1809.00130.pdf)\n",
    "\n",
    "As a result, I have a good idea of the theory and am currently working out how to reverse-engineer the third link which looks most promising. All my notes on this are currently in a word doc.\n",
    "\n",
    "**Current Problems:**\n",
    "* A GAN typically requires 50,000-100,000 images/graphs to train on, and we only have 4 graphs in the example\n",
    "* Having a hard time percieving the third link's input data and how to translate ours to fit its format\n",
    "\n",
    "**Questions:**\n",
    "* How accurate would we want our GAN generator to be? (loss-wise)\n",
    "* Realistically, how many training sessions can we get beyond the 4 that exist in the example json?\n",
    "* Might be possible to generate the data in a way that doesn't require ML. Maybe through bots or something? Do we want the session data to strictly reflect the behavior of human users?\n",
    "* What are we looking for in our model? For it to know a typical series of clicks that the average user might generate? In this case, should we consider an ngram-style neural network we could use as a sequence generator (replacing words with segments), instead?\n",
    "\n",
    "**Input:**\n",
    "* Stop working on GANs. Too much data is required for training.\n",
    "* Start working on ngram NN\n",
    "* Essentially: Predict the next graph in a series of graphs by averaging the past ones\n",
    "* Purpose: Predicting future user activity based on their past activity. But for now, we will be using the activity of multiple users to predict future activity of the average user\n",
    "* Aside: If it so happens that our model does not train well, there’s a chance it’s because the data we’re using is flawed. Inform them of this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram NN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the structure of the segments for good measure (scrap once understood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIDS:  ['session_16527363465571652736427217rawmouseover', 'session_16527363465571652736427318rawscroll', 'session_16527363465571652736428683rawmouseover', 'session_16527363465571652736428699rawmouseover', 'session_16527363465571652736428763rawmouseover', 'session_16527363465571652736428909rawwheel', 'session_16527363465571652736428921rawscroll', 'session_16527363465571652736429603rawmouseover', 'session_16527363465571652736429779rawmouseover', 'session_16527363465571652736429835rawmouseover', 'session_16527363465571652736430013rawmouseover', 'session_16527363465571652736430117rawmouseover', 'session_16527363465571652736433401rawmouseover', 'session_16527363465571652736433433rawmouseover', 'session_16527363465571652736433465rawmouseover', 'session_16527363465571652736434235rawmouseover', 'session_16527363465571652736434331rawmouseover', 'session_16527363465571652736436417rawmouseover', 'session_16527363465571652736436433rawmouseover']\n",
      "NAME:  Games5\n",
      "FIELD NAME:  path\n",
      "LENGTH:  25\n"
     ]
    }
   ],
   "source": [
    "segments = session_0_segments\n",
    "nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "print( \"UIDS: \", nodes[24].get_segment_uids() )\n",
    "print( \"NAME: \", nodes[24].get_segment_name() )\n",
    "print( \"FIELD NAME: \", nodes[24].get_generate_field_name() )\n",
    "print( \"LENGTH: \", len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ngram was scrapped in favor of GNNs until further notice.** See https://arxiv.org/pdf/2202.06081.pdf for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the following sources/tutorials:\n",
    "\n",
    "- General GNN overview information: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- More GNN overview information: https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275\n",
    "- Link Prediction with planetary Cora dataset: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- Graph classification with Heterogeneous data: https://blog.dataiku.com/graph-neural-networks-merging-deep-learning-with-graphs\n",
    "\n",
    "Ultimately decided on building our prototype from the following tutorial due to the fact that we want a model for Link Prediction of homogeneous graphs with complex node structure (Segment objects): https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two\n",
    "Even though the data in this link's graph is heterogeneous, the concept application is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Began implementing the Cora planetary dataset code before realizing their data is very heterogeneous and graph structure seems a little more dissimilar to ours. May revisit if it otherwise becomes especially interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import os\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# os.environ['PYTHONWARNINGS'] = \"ignore\"\n",
    "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('======================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# data = dataset[0]  # Get the first graph object.\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation of the more-relevant heterogeneous graph dataiku tutorial instead:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The \"mean aggregator\" as mentioned in https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two may be especially useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Predict the rating that a given user is likely to give to the most recent movies. This prediction would then be used to suggest the most relevant movie.\n",
    "\n",
    "Modeling: The problem can be modeled as a graph with two types of nodes: one representing users and the other movies. A user node is linked to the movie node if the user has rated the movie and is labeled with the rating.\n",
    "\n",
    "Task: Under this modeling, the problem becomes a link prediction task where the goal is to predict the label (rating) of a link between a user node and a movie node.\n",
    "\n",
    "Their Original code: https://github.com/linafaik08/graph_neural_networks/blob/main/2_link_prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My concerns:\n",
    "- This code depends on user-movie relationships (how do we strip away the user aspect?)\n",
    "- This code uses a KNN approach (maps movies' feature vectors into a vector space and suggests links between nodes in those K classes from there)\n",
    "- Link prediction creates a matrix of all possible edges that could exist between all existent nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our repurposed tutorial code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorials proved too far from the problem to offer anything beyond niche understandings of the link prediction process, so I scraped them. May return back if they prove helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Scratch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Not shown) I tried one version that was very specific to our data, but it started to become a mess with how many transitory methods I had to use to translate the graphs from one state to another and so on. \n",
    "\n",
    "Instead, I eventually decided to go very simple and build from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([1., 2., 3.])\n",
      "y:  tensor([2., 3., 4.])\n",
      "Epoch 100/2000, Loss: 17.388980865478516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 200/2000, Loss: 3.96995210647583\n",
      "Epoch 300/2000, Loss: 0.5636762976646423\n",
      "Epoch 400/2000, Loss: 0.22986499965190887\n",
      "Epoch 500/2000, Loss: 0.19361895322799683\n",
      "Epoch 600/2000, Loss: 0.17265255749225616\n",
      "Epoch 700/2000, Loss: 0.15379761159420013\n",
      "Epoch 800/2000, Loss: 0.13675588369369507\n",
      "Epoch 900/2000, Loss: 0.12140920013189316\n",
      "Epoch 1000/2000, Loss: 0.10762586444616318\n",
      "Epoch 1100/2000, Loss: 0.0953013151884079\n",
      "Epoch 1200/2000, Loss: 0.0843549445271492\n",
      "Epoch 1300/2000, Loss: 0.07469763606786728\n",
      "Epoch 1400/2000, Loss: 0.06620552390813828\n",
      "Epoch 1500/2000, Loss: 0.05872364342212677\n",
      "Epoch 1600/2000, Loss: 0.052088335156440735\n",
      "Epoch 1700/2000, Loss: 0.04614631086587906\n",
      "Epoch 1800/2000, Loss: 0.0407622754573822\n",
      "Epoch 1900/2000, Loss: 0.03582865744829178\n",
      "Epoch 2000/2000, Loss: 0.031272225081920624\n",
      "Nodes: [1, 2, 3, 4]\n",
      "Output: tensor([[2.5076]], grad_fn=<AddmmBackward0>)\n",
      "Predicted next node: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model class\n",
    "class GraphLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(graphs):\n",
    "    X, y = [], []\n",
    "    for graph in graphs:\n",
    "        nodes = list(graph.nodes())\n",
    "        for i in range(len(nodes) - 1):\n",
    "            X.append(np.array(nodes[i]))\n",
    "            y.append(np.array(nodes[i+1]))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the main function to train the model\n",
    "def train_model(graphs, input_size, hidden_size, output_size, num_epochs):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(graphs)\n",
    "    print(\"X: \", X)\n",
    "    print(\"y: \", y)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = GraphLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = model.init_hidden()\n",
    "        loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(X[i], hidden)\n",
    "            loss += criterion(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if ((epoch+1)%100)==0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Test the model on a sample graph with the most basic data\n",
    "if __name__ == '__main__':\n",
    "    # Define a sample graph\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(1,2), (2,3), (2,4), (3,4), (4,1)])\n",
    "\n",
    "    # Train the model on a list of graphs\n",
    "    graphs = [G]\n",
    "    input_size = 1\n",
    "    hidden_size = 10\n",
    "    output_size = 1\n",
    "    num_epochs = 2000\n",
    "    model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "    # Test the model by predicting the next most probable node (after 4) in the graph\n",
    "    input_node = torch.tensor([4], dtype=torch.float32)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_node, hidden)\n",
    "    predicted_node = round( max(output.detach().numpy()[0]) )\n",
    "#     print(f'input node: {input_node}')\n",
    "    print(f'Nodes: {G.nodes()}')\n",
    "    print(f'Output: {output}')\n",
    "    print(f'Predicted next node: {predicted_node}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the same LSTM on arbitrary Object types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leedle lee tensor([[2.0000e-01, 6.8825e+17, 4.7710e+03, 1.9794e+14],\n",
      "        [3.0000e-01, 1.9987e+17, 1.5226e+04, 1.3026e+13],\n",
      "        [4.0000e-01, 6.5419e+17, 2.9260e+03, 2.4404e+14],\n",
      "        [1.0000e-02, 8.2196e+17, 3.7140e+03, 2.6580e+13]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (4x4 and 5x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m objs \u001b[38;5;241m=\u001b[39m [Obj(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.2\u001b[39m), Obj(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.3\u001b[39m), Obj(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morange\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.4\u001b[39m), Obj(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthimble\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilver\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.01\u001b[39m)]\n\u001b[0;32m     79\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m ObjAutoencoder(encoding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Encode an object to a float\u001b[39;00m\n\u001b[0;32m     83\u001b[0m encoded \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mencode(objs[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[49], line 63\u001b[0m, in \u001b[0;36mObjAutoencoder.train\u001b[1;34m(self, objs, epochs, batch_size)\u001b[0m\n\u001b[0;32m     61\u001b[0m batch \u001b[38;5;241m=\u001b[39m x_train[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m     62\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 63\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, batch)\n\u001b[0;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[49], line 50\u001b[0m, in \u001b[0;36mObjAutoencoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 50\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(encoded)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoded\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x4 and 5x4)"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Obj:\n",
    "    # constructor function    \n",
    "    def __init__(self, name, color, weight):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        self.weight = weight\n",
    "        self.id = uuid.uuid4()\n",
    "        self.creation_time = datetime.now()\n",
    "\n",
    "    def to_string(self):\n",
    "        # return f\"Object is named \\\"{self.name}\\\", has a {self.color} color, and weighs {self.weight}lbs with a UUID of {self.id} created at {self.creation_time}.\"\n",
    "        return f\"\\\"{self.name}\\\" created at {self.creation_time}.\"\n",
    "    \n",
    "    def to_array(self):\n",
    "        # Problem is there is no 5th elem\n",
    "        return [float(self.name), float(self.color), float(self.weight), float(self.id.time), float(self.id.clock_seq), \n",
    "                float(self.id.node)]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_array(arr):\n",
    "        obj = Obj(arr[0], arr[1], arr[2])\n",
    "        obj.id = uuid.UUID(arr[3])\n",
    "        obj.creation_time = datetime.fromtimestamp(arr[4])\n",
    "        return obj\n",
    "\n",
    "class ObjAutoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(5, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, 5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def train(self, objs, epochs=100, batch_size=32):\n",
    "        x_train = torch.tensor([obj.to_array() for obj in objs], dtype=torch.float32)\n",
    "        print(\"leedle lee\", x_train)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, x_train.shape[0], batch_size):\n",
    "                batch = x_train[i:i+batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(batch)\n",
    "                loss = loss_fn(outputs, batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def encode(self, obj):\n",
    "        x = torch.tensor(obj.to_array(), dtype=torch.float32)\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded.detach().numpy()\n",
    "\n",
    "    def decode(self, encoded):\n",
    "        decoded = self.decoder(torch.tensor(encoded, dtype=torch.float32))\n",
    "        return Obj.from_array(decoded.detach().numpy())\n",
    "\n",
    "# Example usage\n",
    "objs = [Obj(\"apple\", \"red\", 0.2), Obj(\"banana\", \"yellow\", 0.3), Obj(\"orange\", \"orange\", 0.4), Obj(\"thimble\", \"silver\", 0.01)]\n",
    "autoencoder = ObjAutoencoder(encoding_dim=2)\n",
    "autoencoder.train(objs)\n",
    "\n",
    "# Encode an object to a float\n",
    "encoded = autoencoder.encode(objs[0])\n",
    "print(encoded)\n",
    "\n",
    "# Decode a float to an object\n",
    "decoded = autoencoder.decode(encoded)\n",
    "print(decoded.name, decoded.color, decoded.weight, decoded.id, decoded.creation_time)\n",
    "\n",
    "# obj1 = Obj(\"Apple\", \"red\", 0.5)\n",
    "# obj2 = Obj(\"Airplane\", \"white\", 100000)\n",
    "# obj3 = Obj(\"Thimble\", \"silver\", 0.01)\n",
    "# obj4 = Obj(\"Car\", \"blue\", 5000)\n",
    "# o_lst = [obj1, obj2, obj3, obj4]\n",
    "# o_lst = sorted(o_lst, key=lambda o: o.creation_time)\n",
    "    \n",
    "# o_floats = []\n",
    "# for o in o_lst:\n",
    "#     t = float(o)\n",
    "#     print(\"TENSOR: \", t)\n",
    "#     o_floats.append( t )\n",
    "# n = [o_fl.numpy().tolist() for o_fl in o_floats]\n",
    "# print(\"TENSORS: \", n )\n",
    "# G = make_digraph(n)\n",
    "\n",
    "# for o in o_lst:\n",
    "#   print(o.to_string())\n",
    "\n",
    "# print(\"GRAPH: \", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try plugging our G0,G1,G2,G3 graph data in (work in progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model class\n",
    "class GraphLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(graphs):\n",
    "    X, y = [], []\n",
    "    for graph in graphs:\n",
    "        nodes = list(graph.nodes())\n",
    "        for i in range(len(nodes) - 1):\n",
    "            X.append(np.array(nodes[i]))\n",
    "            y.append(np.array(nodes[i+1]))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the main function to train the model\n",
    "def train_model(graphs, input_size, hidden_size, output_size, num_epochs):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(graphs)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = GraphLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = model.init_hidden()\n",
    "        loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(X[i], hidden)\n",
    "            loss += criterion(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# # Test the model on a sample graph with the most basic data\n",
    "# if __name__ == '__main__':\n",
    "#     # Define a sample graph\n",
    "#     G = nx.DiGraph()\n",
    "#     G.add_edges_from([(1,2), (2,3), (2,4), (3,4), (4,1)])\n",
    "\n",
    "#     # Train the model on a list of graphs\n",
    "#     graphs = [G]\n",
    "#     input_size = 1\n",
    "#     hidden_size = 10\n",
    "#     output_size = 1\n",
    "#     num_epochs = 100\n",
    "#     model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "#     # Test the model by predicting the next node in the graph\n",
    "#     input_node = torch.tensor([4], dtype=torch.float32)\n",
    "#     hidden = model.init_hidden()\n",
    "#     output, hidden = model(input_node, hidden)\n",
    "#     predicted_node = torch.argmax(output).item()\n",
    "#     print(f'Predicted next node: {predicted_node}')\n",
    "\n",
    "# Test the model on a sample graph with the most basic data\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Train the model on a list of graphs\n",
    "    graphs = [G0, G1, G2]\n",
    "    input_size = 3\n",
    "    hidden_size = 10\n",
    "    output_size = 1\n",
    "    num_epochs = 100\n",
    "    model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "    # Test the model by predicting the next node in the graph\n",
    "    \n",
    "    # Problem: G3 needs to be turned into an embedding of type float32\n",
    "    input_node = torch.tensor([G3], dtype=torch.float32)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_node, hidden)\n",
    "    predicted_node = max(output.tolist())\n",
    "#     print(f'input node: {input_node}')\n",
    "    print(f'Nodes: {G.nodes()}')\n",
    "    print(f'Output: {output.tolist()}')\n",
    "    print(f'Predicted next node: {predicted_node}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next objective:** Find a way to translate the segment objects into autoencoded embeddings for training before translating them back into the predicted output segment we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee3d06e2f47c379c84ddc2f8584ef1b36487d010a572cd3eb9e58b6881766743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
