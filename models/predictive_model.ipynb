{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Prediction Model\n",
    "In this notebook, we run through an experiment using UserALE data generated within an instantiation of Superset.  This data reflects four simulated user sessions in which the user performs three tasks within the Video Game Sales example dashboard:\n",
    "\n",
    "1. Filter the games for Wii, Racing, and Nintendo.\n",
    "2. Find Mario Kart in the list of games.\n",
    "3. Determine the difference in global sales between the 3DS game Nintendogs + cats and Wii Sports.\n",
    "\n",
    "The data of these four sessions is captured in a json file within the data folder entitled `task_example.json`.  In this experiment, we will:\n",
    "\n",
    "* Experiment with the efficacy of several predictive models to determine which is the best for our objective\n",
    "* Attempt to plug the `DiGraph` objects resulting from `task_example.json` into the model we choose\n",
    "* Tune the resulting model to minimize loss and maximize prediction accuracy\n",
    "\n",
    "**Note: The data utilized in this example was not data collected in any user study.  Rather this data is simulated through developer interactions with the Superset dashboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code:\n",
    "\n",
    "Generates the graph lists and structures that we'll eventually use for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import datetime\n",
    "import distill\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "def setup(file, date_type):\n",
    "    with open(file) as json_file:\n",
    "        raw_data = json.load(json_file)\n",
    "\n",
    "    data = {}\n",
    "    for log in raw_data:\n",
    "        data[distill.getUUID(log)] = log\n",
    "        \n",
    "    # Convert clientTime to specified type\n",
    "    for uid in data:\n",
    "        log = data[uid]\n",
    "        client_time = log['clientTime']\n",
    "        if date_type == \"integer\":\n",
    "            log['clientTime'] = distill.epoch_to_datetime(client_time)\n",
    "        elif date_type == \"datetime\":\n",
    "            log['clientTime'] = pd.to_datetime(client_time, unit='ms', origin='unix')\n",
    "\n",
    "    # Sort\n",
    "    sorted_data = sorted(data.items(), key=lambda kv: kv[1]['clientTime'])\n",
    "    sorted_dict = dict(sorted_data)\n",
    "\n",
    "    return (sorted_data, sorted_dict)\n",
    "\n",
    "def draw_digraph(segments):\n",
    "    nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "    edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "    \n",
    "    # Set coloring of graph based on element in Superset dashboard\n",
    "    color_map = []\n",
    "    for segment in segments:\n",
    "        if re.match(\"Game_Filter\\S*\", segment.segment_name):\n",
    "            color_map.append('green')\n",
    "        else:\n",
    "            color_map.append('blue')\n",
    "    \n",
    "    graph = distill.createDiGraph(nodes, edges)\n",
    "    nx.draw(graph, node_color=color_map)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_many_session = setup(\"./data/task_example.json\", \"datetime\")\n",
    "sorted_dict = data_many_session[1]\n",
    "\n",
    "# Create segments based on sessionID\n",
    "segments = distill.Segments()\n",
    "session_ids = sorted(distill.find_meta_values('sessionID', sorted_dict), key=lambda sessionID: sessionID)\n",
    "for session_id in session_ids:\n",
    "    segments.append_segments(distill.generate_collapsing_window_segments(sorted_dict, 'sessionID', [session_id], session_id))\n",
    "    \n",
    "# Improve readability of Segment names\n",
    "for index in range(len(segments)):\n",
    "    segments[index].segment_name = \"Session\" + str(index)\n",
    "    \n",
    "    \n",
    "segment_names = [segment.segment_name for segment in segments]\n",
    "start_end_vals = [segment.start_end_val for segment in segments]\n",
    "segment_map = distill.write_segment(sorted_dict, segment_names, start_end_vals)\n",
    "\n",
    "session_0_segments = distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_1_segments = distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_2_segments = distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_3_segments = distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "\n",
    "session_0_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_1_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_2_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_3_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "\n",
    "segments.append_segments(session_0_segments)\n",
    "segments.append_segments(session_1_segments)\n",
    "segments.append_segments(session_2_segments)\n",
    "segments.append_segments(session_3_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example user-activity graph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G0 = draw_digraph(session_0_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code found at https://towardsdatascience.com/build-a-super-simple-gan-in-pytorch-54ba349920e4\n",
    "\n",
    "Very basic task: Training a GAN to generate positive integers using vectors of their binary encodings (Ex: 56 is 0111000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def create_binary_list_from_int(number: int) -> List[int]:\n",
    "    if number < 0 or type(number) is not int:\n",
    "        raise ValueError(\"Only Positive integers are allowed\")\n",
    "\n",
    "    return [int(x) for x in list(bin(number))[2:]]\n",
    "\n",
    "def generate_even_data(max_int: int, batch_size: int=16) -> Tuple[List[int], List[List[int]]]:\n",
    "    # Get the number of binary places needed to represent the maximum number\n",
    "    max_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Sample batch_size number of integers in range 0-max_int\n",
    "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
    "\n",
    "    # create a list of labels all ones because all numbers are even\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    # Generate a list of binary numbers for training.\n",
    "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
    "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
    "\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Generator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense = nn.Linear(int(input_length), 1);\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 201):\n",
    "    input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Models\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    # Optimizers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "    # loss\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Create noisy input for generator\n",
    "        # Need float type instead of int\n",
    "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "        \n",
    "        # Generate examples of even real data\n",
    "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
    "        true_labels = torch.tensor(true_labels).unsqueeze(1).float()\n",
    "        true_data = torch.tensor(true_data).float()\n",
    "\n",
    "        # Train the generator\n",
    "        # We invert the labels here and don't train the discriminator because we want the generator\n",
    "        # to make things the discriminator classifies as true.\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        # Print generator's loss at every 50th step\n",
    "        if (i % 50)==0 :\n",
    "          print(\"STEP \", str(i))\n",
    "          print(generator_loss)\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        z = torch.zeros(batch_size).unsqueeze(1)\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, z)\n",
    "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP  0\n",
      "tensor(0.6884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  50\n",
      "tensor(0.6701, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  100\n",
      "tensor(0.6547, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  150\n",
      "tensor(0.6683, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  200\n",
      "tensor(0.6806, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So essentially what we'd do for the graphs is, instead of feeding integers, we would feed session data. Feature vectors would represent [div_1, div_2, ..., div_n] with each element denoting whether or not an element was clicked at that segment of the session (vertex of the graph). Only problem is, human-made session data is not so easily generated as it is with random numbers in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary so far:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I've read:\n",
    "* (GAN theory) https://www.frontiersin.org/articles/10.3389/fdata.2019.00003/full\n",
    "* (undirected graphs GAN with tensorflow) https://github.com/hwwang55/GraphGAN (further documentation: https://arxiv.org/pdf/1711.08267.pdf)\n",
    "* (directed graphs GAN with pytorch) https://github.com/THUDM/GraphSGAN (further documentation: https://arxiv.org/pdf/1809.00130.pdf)\n",
    "\n",
    "As a result, I have a good idea of the theory and am currently working out how to reverse-engineer the third link which looks most promising. All my notes on this are currently in a word doc.\n",
    "\n",
    "**Current Problems:**\n",
    "* A GAN typically requires 50,000-100,000 images/graphs to train on, and we only have 4 graphs in the example\n",
    "* Having a hard time percieving the third link's input data and how to translate ours to fit its format\n",
    "\n",
    "**Questions:**\n",
    "* How accurate would we want our GAN generator to be? (loss-wise)\n",
    "* Realistically, how many training sessions can we get beyond the 4 that exist in the example json?\n",
    "* Might be possible to generate the data in a way that doesn't require ML. Maybe through bots or something? Do we want the session data to strictly reflect the behavior of human users?\n",
    "* What are we looking for in our model? For it to know a typical series of clicks that the average user might generate? In this case, should we consider an ngram-style neural network we could use as a sequence generator (replacing words with segments), instead?\n",
    "\n",
    "**Input:**\n",
    "* Stop working on GANs. Too much data is required for training.\n",
    "* Start working on ngram NN\n",
    "* Essentially: Predict the next graph in a series of graphs by averaging the past ones\n",
    "* Purpose: Predicting future user activity based on their past activity. But for now, we will be using the activity of multiple users to predict future activity of the average user\n",
    "* Aside: If it so happens that our model does not train well, there’s a chance it’s because the data we’re using is flawed. Inform them of this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram NN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the structure of the segments for good measure (scrap once understood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIDS:  ['session_16527363465571652736427217rawmouseover', 'session_16527363465571652736427318rawscroll', 'session_16527363465571652736428683rawmouseover', 'session_16527363465571652736428699rawmouseover', 'session_16527363465571652736428763rawmouseover', 'session_16527363465571652736428909rawwheel', 'session_16527363465571652736428921rawscroll', 'session_16527363465571652736429603rawmouseover', 'session_16527363465571652736429779rawmouseover', 'session_16527363465571652736429835rawmouseover', 'session_16527363465571652736430013rawmouseover', 'session_16527363465571652736430117rawmouseover', 'session_16527363465571652736433401rawmouseover', 'session_16527363465571652736433433rawmouseover', 'session_16527363465571652736433465rawmouseover', 'session_16527363465571652736434235rawmouseover', 'session_16527363465571652736434331rawmouseover', 'session_16527363465571652736436417rawmouseover', 'session_16527363465571652736436433rawmouseover']\n",
      "NAME:  Games5\n",
      "FIELD NAME:  path\n",
      "LENGTH:  25\n"
     ]
    }
   ],
   "source": [
    "segments = session_0_segments\n",
    "nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "print( \"UIDS: \", nodes[24].get_segment_uids() )\n",
    "print( \"NAME: \", nodes[24].get_segment_name() )\n",
    "print( \"FIELD NAME: \", nodes[24].get_generate_field_name() )\n",
    "print( \"LENGTH: \", len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ngram was scrapped in favor of GNNs until further notice.** See https://arxiv.org/pdf/2202.06081.pdf for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the following sources/tutorials:\n",
    "\n",
    "- General GNN overview information: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- More GNN overview information: https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275\n",
    "- Link Prediction with planetary Cora dataset: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- Graph classification with Heterogeneous data: https://blog.dataiku.com/graph-neural-networks-merging-deep-learning-with-graphs\n",
    "\n",
    "Ultimately decided on building our prototype from the following tutorial due to the fact that we want a model for Link Prediction of homogeneous graphs with complex node structure (Segment objects): https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two\n",
    "Even though the data in this link's graph is heterogeneous, the concept application is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Began implementing the Cora planetary dataset code before realizing their data is very heterogeneous and graph structure seems a little more dissimilar to ours. May revisit if it otherwise becomes especially interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import os\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# os.environ['PYTHONWARNINGS'] = \"ignore\"\n",
    "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('======================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# data = dataset[0]  # Get the first graph object.\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation of the more-relevant heterogeneous graph dataiku tutorial instead:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The \"mean aggregator\" as mentioned in https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two may be especially useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Predict the rating that a given user is likely to give to the most recent movies. This prediction would then be used to suggest the most relevant movie.\n",
    "\n",
    "Modeling: The problem can be modeled as a graph with two types of nodes: one representing users and the other movies. A user node is linked to the movie node if the user has rated the movie and is labeled with the rating.\n",
    "\n",
    "Task: Under this modeling, the problem becomes a link prediction task where the goal is to predict the label (rating) of a link between a user node and a movie node.\n",
    "\n",
    "Their Original code: https://github.com/linafaik08/graph_neural_networks/blob/main/2_link_prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My concerns:\n",
    "- This code depends on user-movie relationships (how do we strip away the user aspect?)\n",
    "- This code uses a KNN approach (maps movies' feature vectors into a vector space and suggests links between nodes in those K classes from there)\n",
    "- Link prediction creates a matrix of all possible edges that could exist between all existent nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our repurposed tutorial code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorials proved too far from the problem to offer anything beyond niche understandings of the link prediction process, so I scraped them. May return back if they prove helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Scratch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Not shown) I tried one version that was very specific to our data, but it started to become a mess with how many transitory methods I had to use to translate the graphs from one state to another and so on. \n",
    "\n",
    "Instead, I eventually decided to go very simple and build from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([1., 2., 3.])\n",
      "y:  tensor([2., 3., 4.])\n",
      "Epoch 100/2000, Loss: 15.911482810974121\n",
      "Epoch 200/2000, Loss: 2.4222187995910645\n",
      "Epoch 300/2000, Loss: 0.6171603202819824\n",
      "Epoch 400/2000, Loss: 0.4610625207424164\n",
      "Epoch 500/2000, Loss: 0.37916502356529236\n",
      "Epoch 600/2000, Loss: 0.30773019790649414\n",
      "Epoch 700/2000, Loss: 0.2461182028055191\n",
      "Epoch 800/2000, Loss: 0.19465607404708862\n",
      "Epoch 900/2000, Loss: 0.15378272533416748\n",
      "Epoch 1000/2000, Loss: 0.12316189706325531\n",
      "Epoch 1100/2000, Loss: 0.10104291886091232\n",
      "Epoch 1200/2000, Loss: 0.08503887057304382\n",
      "Epoch 1300/2000, Loss: 0.07301736623048782\n",
      "Epoch 1400/2000, Loss: 0.06337552517652512\n",
      "Epoch 1500/2000, Loss: 0.05501730740070343\n",
      "Epoch 1600/2000, Loss: 0.04724908992648125\n",
      "Epoch 1700/2000, Loss: 0.0396733358502388\n",
      "Epoch 1800/2000, Loss: 0.032097429037094116\n",
      "Epoch 1900/2000, Loss: 0.02447284571826458\n",
      "Epoch 2000/2000, Loss: 0.01692412793636322\n",
      "Nodes: [1, 2, 3, 4]\n",
      "Output: tensor([[2.8604]], grad_fn=<AddmmBackward0>)\n",
      "Predicted next node: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model class\n",
    "class GraphLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(graphs):\n",
    "    X, y = [], []\n",
    "    for graph in graphs:\n",
    "        nodes = list(graph.nodes())\n",
    "        for i in range(len(nodes) - 1):\n",
    "            X.append(np.array(nodes[i]))\n",
    "            y.append(np.array(nodes[i+1]))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the main function to train the model\n",
    "def train_model(graphs, input_size, hidden_size, output_size, num_epochs):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(graphs)\n",
    "    print(\"X: \", X)\n",
    "    print(\"y: \", y)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = GraphLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = model.init_hidden()\n",
    "#         loss = torch.zeros(size=(1,), requires_grad=True)\n",
    "        loss = torch.zeros(1)\n",
    "        for i in range(X.shape[0]):\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(X[i], hidden)\n",
    "            loss += criterion(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if ((epoch+1)%100)==0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Test the model on a sample graph with the most basic data\n",
    "if __name__ == '__main__':\n",
    "    # Define a sample graph\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(1,2), (2,3), (2,4), (3,4), (4,1)])\n",
    "\n",
    "    # Train the model on a list of graphs\n",
    "    graphs = [G]\n",
    "    input_size = 1\n",
    "    hidden_size = 10\n",
    "    output_size = 1\n",
    "    num_epochs = 2000\n",
    "    model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "    # Test the model by predicting the next most probable node (after 4) in the graph\n",
    "    input_node = torch.tensor([4], dtype=torch.float32)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_node, hidden)\n",
    "    predicted_node = round( max(output.detach().numpy()[0]) )\n",
    "    print(f'Nodes: {G.nodes()}')\n",
    "    print(f'Output: {output}')\n",
    "    print(f'Predicted next node: {predicted_node}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary Goal Accomplished:** Prove LSTM sequential prediction works with simple float types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the same LSTM on more complicated arbitrary Object types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll build an autoencoder that embeds the arbitrary Object types into numeric floats we can plug into an LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:  tensor([[2.0000e-01, 9.9288e+17, 1.0940e+04, 1.7524e+14, 1.6803e+09],\n",
      "        [3.0000e-01, 1.0802e+18, 6.7800e+03, 1.3068e+14, 1.6803e+09],\n",
      "        [4.0000e-01, 7.8197e+15, 1.1960e+03, 2.5959e+14, 1.6803e+09],\n",
      "        [1.0000e-02, 3.2056e+17, 1.2872e+04, 1.4478e+14, 1.6803e+09]])\n",
      "TEST OBJECT:  name:  apple color:  red weight:  0.2 id:  1a6fcba6-6c08-4dc7-aabc-9f610d451959 creation time:  2023-03-31 15:51:44.090629\n",
      "OBJ ARRAY:  [0.2, 9.928810249175561e+17, 10940.0, 175239183276377.0, 1680292304.090629]\n",
      "OBJ FLOAT TENSOR:  tensor([2.0000e-01, 9.9288e+17, 1.0940e+04, 1.7524e+14, 1.6803e+09])\n",
      "ENCODED:  [9.0159945e+16]\n",
      "DECODED FLOAT TENSOR:  tensor([0., 1., 0., 0., 0.], grad_fn=<SigmoidBackward0>)\n",
      "DECODED ARRAY:  [0. 1. 0. 0. 0.]\n",
      "DECODED OBJ:  name:   color:   weight:  0.0 id:  00000001-0000-0000-0000-000000000000 creation time:  1969-12-31 19:00:00\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Obj:\n",
    "    # constructor function    \n",
    "    def __init__(self, name, color, weight):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        self.weight = weight\n",
    "        self.id = uuid.uuid4()\n",
    "        self.creation_time = datetime.now()\n",
    "\n",
    "    def to_string(self):\n",
    "        # return f\"Object is named \\\"{self.name}\\\", has a {self.color} color, and weighs {self.weight}lbs with a UUID of {self.id} created at {self.creation_time}.\"\n",
    "        return f\"\\\"{self.name}\\\" created at {self.creation_time}.\"\n",
    "    \n",
    "    def to_array(self):\n",
    "        # First problem was it was attempting to convert strings to floats\n",
    "        # Second problem is there is no 5th elem\n",
    "        # Third problem is UUID translation\n",
    "        # No more problems\n",
    "        return [float(self.weight), float(self.id.time), float(self.id.clock_seq), \n",
    "                float(self.id.node), float(self.creation_time.timestamp())]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_array(arr):\n",
    "        print(\"DECODED ARRAY: \", arr)\n",
    "        weight = arr[0]\n",
    "        \n",
    "#         print(\"ID_TIME: \", arr[1])\n",
    "        id_time = int(arr[1])\n",
    "#         print(\"ID_TIME: \", id_time)\n",
    "        id_clock_seq = int(arr[2])\n",
    "#         print(\"ID_CLOCK_SEQ: \", id_clock_seq)\n",
    "        id_node = int(arr[3])\n",
    "#         print(\"ID_NODE: \", id_node)\n",
    "        #First 32 bits of UUID\n",
    "        time_low = id_time & 0xFFFFFFFF\n",
    "#         print(\"TIME_LOW: \", time_low)\n",
    "        #Next 16 bits\n",
    "        time_mid = (id_time >> 32) & 0xFFFF\n",
    "#         print(\"TIME_MID: \", time_mid)\n",
    "        #Next 16 bits\n",
    "        time_hi_version = (id_time >> 48) & 0x0FFF\n",
    "#         print(\"TIME_HI_VERSION: \", time_hi_version)\n",
    "        #Next 8 bits\n",
    "        clock_seq_hi_variant = (id_clock_seq >> 8) & 0xFF\n",
    "#         print(\"CLOCK_SEQ_HI_VARIANT: \", clock_seq_hi_variant)\n",
    "        #Next 8 bits\n",
    "        clock_seq_low = id_clock_seq & 0xFF\n",
    "#         print(\"CLOCK_SEQ_LOW: \", clock_seq_low)\n",
    "        #Last 48 bits\n",
    "        node = id_node.to_bytes(6, byteorder='big')\n",
    "        fields = (time_low, time_mid, time_hi_version, clock_seq_hi_variant, clock_seq_low, int.from_bytes(node, byteorder='big'))\n",
    "        \n",
    "        timestamp = int(arr[4].item())\n",
    "        creation_time = datetime.fromtimestamp(timestamp)\n",
    "        \n",
    "        obj = Obj(\"\", \"\", weight) #Empty strings are used in place of None types for name/color\n",
    "        obj.id = uuid.UUID(fields=fields)\n",
    "        obj.creation_time = creation_time\n",
    "        return obj\n",
    "\n",
    "class ObjAutoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim): #HERE IS THE PROBLEM\n",
    "        super().__init__()\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(5, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, 5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def train(self, objs, epochs=100, batch_size=32):\n",
    "        x_train = torch.tensor([obj.to_array() for obj in objs], dtype=torch.float32)\n",
    "        print(\"TRAINING DATA: \", x_train)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, x_train.shape[0], batch_size):\n",
    "                batch = x_train[i:i+batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(batch)\n",
    "                loss = loss_fn(outputs, batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def encode(self, obj):\n",
    "        a = obj.to_array()\n",
    "        print(\"OBJ ARRAY: \", a)\n",
    "        x = torch.tensor(a, dtype=torch.float32)\n",
    "        print(\"OBJ FLOAT TENSOR: \", x) \n",
    "        encoded = self.encoder(x)\n",
    "        return encoded.detach().numpy()\n",
    "\n",
    "    def decode(self, encoded):\n",
    "        decoded = self.decoder(torch.tensor(encoded, dtype=torch.float32))\n",
    "        print(\"DECODED FLOAT TENSOR: \", decoded) #Why is decoded translation so poor? Not enough data?\n",
    "        return Obj.from_array(decoded.detach().numpy())\n",
    "\n",
    "# Example usage\n",
    "objs = [Obj(\"apple\", \"red\", 0.2), Obj(\"banana\", \"yellow\", 0.3), Obj(\"orange\", \"orange\", 0.4), Obj(\"thimble\", \"silver\", 0.01)]\n",
    "autoencoder = ObjAutoencoder(encoding_dim=1)\n",
    "autoencoder.train(objs)\n",
    "\n",
    "# Encode an object to a float\n",
    "t = objs[0]\n",
    "print(\"TEST OBJECT: \", \"name: \", t.name, \"color: \", t.color, \"weight: \", t.weight,\"id: \", t.id, \"creation time: \", t.creation_time)\n",
    "encoded = autoencoder.encode(t)\n",
    "print(\"ENCODED: \", encoded)\n",
    "\n",
    "# Decode a float to an object\n",
    "decoded = autoencoder.decode(encoded)\n",
    "print(\"DECODED OBJ: \", \"name: \", decoded.name, \"color: \", decoded.color, \"weight: \", decoded.weight,\"id: \", decoded.id, \"creation time: \", decoded.creation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Currently cannot use/predict string types and data integrity (uuid and datetimes) is lost in translation. Maybe the integrity is lost because of the autoencoder structure? Or maybe this has to do with not having enough training data? Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plug a graph of embedded floats into our LSTM as training data to generate the next likely Object type in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJ ARRAY:  [0.2, 9.928810249175561e+17, 10940.0, 175239183276377.0, 1680292304.090629]\n",
      "OBJ FLOAT TENSOR:  tensor([2.0000e-01, 9.9288e+17, 1.0940e+04, 1.7524e+14, 1.6803e+09])\n",
      "OBJ ARRAY:  [0.3, 1.08023546804038e+18, 6780.0, 130680203930924.0, 1680292304.090629]\n",
      "OBJ FLOAT TENSOR:  tensor([3.0000e-01, 1.0802e+18, 6.7800e+03, 1.3068e+14, 1.6803e+09])\n",
      "OBJ ARRAY:  [0.4, 7819746284398064.0, 1196.0, 259593556815855.0, 1680292304.090629]\n",
      "OBJ FLOAT TENSOR:  tensor([4.0000e-01, 7.8197e+15, 1.1960e+03, 2.5959e+14, 1.6803e+09])\n",
      "OBJ ARRAY:  [0.01, 3.205604809978208e+17, 12872.0, 144776519464944.0, 1680292304.090629]\n",
      "OBJ FLOAT TENSOR:  tensor([1.0000e-02, 3.2056e+17, 1.2872e+04, 1.4478e+14, 1.6803e+09])\n",
      "X:  tensor([9.0160e+16, 9.8087e+16, 7.3177e+14])\n",
      "y:  tensor([9.8087e+16, 7.3177e+14, 2.9116e+16])\n",
      "Epoch 100/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 200/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 300/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 400/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 500/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 600/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 700/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 800/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 900/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1000/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1100/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1200/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1300/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1400/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1500/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1600/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1700/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1800/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 1900/2000, Loss: 1.0469406227101136e+34\n",
      "Epoch 2000/2000, Loss: 1.0469406227101136e+34\n",
      "Nodes: [9.0159945e+16, 9.808725e+16, 731773500000000.0, 2.911635e+16]\n",
      "Output: tensor([[5.1151]], grad_fn=<AddmmBackward0>)\n",
      "DECODED FLOAT TENSOR:  tensor([0.1541, 0.5745, 0.2561, 0.3550, 0.3699], grad_fn=<SigmoidBackward0>)\n",
      "DECODED ARRAY:  [0.15408875 0.5745409  0.25610003 0.35501125 0.36990768]\n",
      "Decoded Output:  name:   color:   weight:  0.15408875 id:  00000000-0000-0000-0000-000000000000 creation time:  1969-12-31 19:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_2808\\2832909376.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  decoded = self.decoder(torch.tensor(encoded, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a sample graph with the most basic data\n",
    "\n",
    "# Sort the list of objects according to each object's creation time\n",
    "objs.sort(key=lambda x: x.creation_time, reverse=True)\n",
    "# For each object, append its numeric encoding to the list of encoded_objects\n",
    "encoded_objs = []\n",
    "for o in objs:\n",
    "    e = autoencoder.encode(o)\n",
    "    encoded_objs.append(e[0]) #Accessing first element for float value, try just \"e\", too\n",
    "# Define a sample graph with our embedded objects\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(encoded_objs[0],encoded_objs[1]), (encoded_objs[1],encoded_objs[2]), (encoded_objs[1],encoded_objs[3]), \n",
    "                  (encoded_objs[2],encoded_objs[3]), (encoded_objs[3],encoded_objs[0])])\n",
    "\n",
    "# Train the model on a list of graphs (just one for now, becuase generating so many is annoying)\n",
    "graphs = [G]\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "num_epochs = 2000\n",
    "model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "# Test the model by predicting the next most probable node (after the most recently created obj) in the graph\n",
    "input_node = torch.tensor([encoded_objs[3]], dtype=torch.float32)\n",
    "hidden = model.init_hidden()\n",
    "output, hidden = model(input_node, hidden)\n",
    "print(f'Nodes: {G.nodes()}')\n",
    "print(f'Output: {output}')\n",
    "decoded = autoencoder.decode(output[0])\n",
    "print('Decoded Output: ', \"name: \", decoded.name, \"color: \", decoded.color, \"weight: \", decoded.weight,\"id: \", decoded.id, \"creation time: \", decoded.creation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Our output encodings seem to be leagues away from the embedding values they're trained off of and if embeddings are zero, it doesn't train at all. Maybe this has to do with the LSTM structure (before it trained/outputed simple floats, now it trains/outputs large ones)? Or maybe this has to do with not having enough training data? Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try plugging our G0,G1,G2,G3 graph data in by first, creating an autoencoder for Segment types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment objects for reference (NOT MEANT TO BE RUN):\n",
    "\n",
    "class Segment_Type(Enum):\n",
    "    CREATE = \"create\"\n",
    "    GENERATE = \"generate\"\n",
    "    DEADSPACE = \"deadspace\"\n",
    "    FIXED_TIME = \"fixed_time\"\n",
    "    GENERATE_COLLAPSING_WINDOWS = \"generate_collapsing_windows\"\n",
    "    UNION = \"union\"\n",
    "    INTERSECTION = \"intersection\"\n",
    "    DIFFERENCE = \"difference\"\n",
    "\n",
    "class Segment():\n",
    "    \"\"\"\n",
    "    Distill's segmentation package. Allows the user to segment User Ale log data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_name=\"\", start_end_val=None, num_logs=0, uids=[]):\n",
    "        \"\"\"\n",
    "        Initializes a Segment object.  This object contains metadata for the associated Segment.\n",
    "        :param segment_name: Name associated with the segment, defaults to an empty string\n",
    "        :param start_end_val: A list of tuples (i.e [(start_time, end_time)], where start_time and end_time are Date/Time Objects or integers.  Defaults to a None value.\n",
    "        :param num_logs: Number of logs in the segment.  Defaults to 0.\n",
    "        :param uids: A list of strings representing the associated uids of logs within the segment. Defaults to an empty list.\n",
    "        \"\"\"\n",
    "\n",
    "        self.segment_name = segment_name # string\n",
    "        self.start_end_val = start_end_val # a list of tuples (i.e [(start_time, end_time)], where start_time and end_time are Date/Time Objects or integers.  Defaults to a None value.\n",
    "        self.num_logs = num_logs # int\n",
    "        self.uids = uids # list of uuids\n",
    "        self.generate_field_name = None # string\n",
    "        self.generate_matched_values = None # list of values\n",
    "        self.segment_type = None # Enumerated type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 2000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 3000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 4000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 5000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 6000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 7000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 8000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 9000/10000, Loss: 470901760521666560.0000\n",
      "Epoch 10000/10000, Loss: 470901760521666560.0000\n",
      "Encoded Segment 7: -66757396.0\n",
      "[-61077808.0, -18881196.0, 23270642.0, 30889696.0, -42210172.0, 52457560.0, 3410816.25, 14296680.0, -24459824.0]\n",
      "DECODED:  name:   start_end_val:  [(0, 0)] num_logs:  -66012020.0 uids:  []\n",
      "Decoded Segment 7: <__main__.Segment object at 0x0000021E542A7790>\n",
      "Decoded Segment 7: segment_name:   start_end_val:  [(0, 0)] num_logs:  -66012020.0 uids:  [] generate_field_name:  None generate_matched_values:  None segment_type:  None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "class Segment_Type(Enum):\n",
    "    CREATE = \"create\"\n",
    "    GENERATE = \"generate\"\n",
    "    DEADSPACE = \"deadspace\"\n",
    "    FIXED_TIME = \"fixed_time\"\n",
    "    GENERATE_COLLAPSING_WINDOWS = \"generate_collapsing_windows\"\n",
    "    UNION = \"union\"\n",
    "    INTERSECTION = \"intersection\"\n",
    "    DIFFERENCE = \"difference\"\n",
    "\n",
    "def string_to_float_ascii_list(s):\n",
    "    ascii_list = []\n",
    "    for char in s:\n",
    "        ascii_list.append(ord(char))\n",
    "    return ascii_list\n",
    "\n",
    "def ascii_list_to_string(ascii_list):\n",
    "    print(ascii_list)\n",
    "    s = \"\"\n",
    "    for ascii_value in ascii_list:\n",
    "        if ascii_value >= 0 and ascii_value <= 127:\n",
    "            s += chr(ascii_value)\n",
    "    return s\n",
    "\n",
    "def uuid_to_float_list(id):\n",
    "    lst = [float(id.time), float(id.clock_seq), float(id.node)]\n",
    "    return lst\n",
    "\n",
    "def seg_to_array(segment):\n",
    "    name_lst = string_to_float_ascii_list(segment.segment_name)\n",
    "    start_end_tup = segment.start_end_val[0]\n",
    "    segment_array = np.array([[float(start_end_tup[0].timestamp()), float(start_end_tup[1].timestamp()), \n",
    "                               float(segment.num_logs)] + name_lst])\n",
    "    return segment_array\n",
    "\n",
    "def array_to_seg(arr):\n",
    "    start, end, num_logs = arr[:3]\n",
    "    name = ascii_list_to_string(arr[3:])\n",
    "#     start_end_val = [(datetime.fromtimestamp(start), datetime.fromtimestamp(end))]\n",
    "    start_end_val = [(0, 0)]\n",
    "    uids = []\n",
    "    print(\"DECODED: \", \"name: \", name, \"start_end_val: \", start_end_val, \"num_logs: \", num_logs, \"uids: \", uids)\n",
    "    seg = Segment(name, start_end_val, num_logs, uids)\n",
    "    return seg\n",
    "    \n",
    "class SegmentAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SegmentAutoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = torch.nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, segments, lr=0.1, batch_size=32, num_epochs=100):\n",
    "        # Convert segments to arrays\n",
    "        segment_arrays = [seg_to_array(seg) for seg in segments]\n",
    "        segment_arrays = np.concatenate(segment_arrays, axis=0)\n",
    "\n",
    "        # Create PyTorch DataLoader\n",
    "        dataset = torch.utils.data.TensorDataset(torch.Tensor(segment_arrays))\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Define optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # Train loop\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                inputs = batch[0]\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "#             epoch_loss = running_loss / len(segment_arrays)\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            if (epoch+1)%1000 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            # Call the train() method of the parent class to update the parameters\n",
    "            super(SegmentAutoencoder, self).train()\n",
    "\n",
    "    def encode(self, segment):\n",
    "        # Make segment_name into some function of its ascii numeric values - or word2vec\n",
    "        # Combine start_end_val datetime tuple element floats as a single float\n",
    "        # Keep num_logs the same value\n",
    "        # Convert uids list into floats that combine into a single float\n",
    "        segment_array = seg_to_array(segment)\n",
    "#         print(\"segment_array: \", segment_array)\n",
    "#         segment_array = np.array([[len(segment.uids), len(segment.segment_name)]])\n",
    "        with torch.no_grad():\n",
    "            encoded = self.encoder(torch.Tensor(segment_array))\n",
    "        return encoded.squeeze().tolist()\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        # Convert all of the floats from the encoded value(s) back\n",
    "        encoded = np.array(encoded)\n",
    "        encoded = encoded.reshape((1, -1))  # Reshape to (1, latent_dim) - dimensionality of the latent space\n",
    "        with torch.no_grad():\n",
    "            decoded = self.decoder(torch.Tensor(encoded))\n",
    "        decoded = [i for i in decoded.squeeze().tolist()]\n",
    "        seg = array_to_seg(decoded)\n",
    "        return seg\n",
    "\n",
    "# Create some Segment objects\n",
    "segments = []\n",
    "seg1 = distill.Segment(segment_name=\"Segment 1\", start_end_val=[(datetime.now(), datetime.now())], num_logs=1, uids=[\"uid1\", \"uid2\", \"uid3\", \"uid4\", \"uid5\"])\n",
    "seg2 = distill.Segment(\"Segment 2\", [(datetime.now(), datetime.now())], 2, [\"uid6\", \"uid7\", \"uid8\"])\n",
    "seg3 = distill.Segment(\"Segment 3\", [(datetime.now(), datetime.now())], 3, [\"uid9\", \"uid10\", \"uid11\",\"uid12\"])\n",
    "seg4 = distill.Segment(\"Segment 4\", [(datetime.now(), datetime.now())], 4, [\"uid13\", \"uid14\"])\n",
    "seg5 = distill.Segment(\"Segment 5\", [(datetime.now(), datetime.now())], 5, [\"uid15\", \"uid16\"])\n",
    "seg6 = distill.Segment(\"Segment 6\", [(datetime.now(), datetime.now())], 6, [\"uid17\", \"uid18\", \"uid19\"])\n",
    "segments.append(seg1)\n",
    "segments.append(seg2)\n",
    "segments.append(seg3)\n",
    "segments.append(seg4)\n",
    "segments.append(seg5)\n",
    "segments.append(seg6)\n",
    "\n",
    "# Initialize the autoencoder\n",
    "input_size = 12\n",
    "hidden_size = 1 #doubles as the encoding dimension\n",
    "autoencoder = SegmentAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Train the autoencoder on the Segment objects\n",
    "autoencoder.train(segments, num_epochs=10000)\n",
    "\n",
    "# Convert a Segment object to a float using the trained autoencoder\n",
    "seg7 = Segment(\"Segment 7\", [(datetime.now(), datetime.now())], 7, [\"uid20\", \"uid21\", \"uid22\"])\n",
    "encoded = autoencoder.encode(seg7)\n",
    "print(\"Encoded Segment 7:\", encoded)\n",
    "decoded = autoencoder.decode(encoded)\n",
    "print(\"Decoded Segment 7:\", decoded)\n",
    "print(\"Decoded Segment 7:\", \"segment_name: \", decoded.segment_name, \"start_end_val: \", decoded.start_end_val, \n",
    "      \"num_logs: \", decoded.num_logs,\"uids: \", decoded.uids, \"generate_field_name: \", decoded.generate_field_name, \n",
    "      \"generate_matched_values: \", decoded.generate_matched_values, \"segment_type: \", decoded.segment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "class Segment_Type(Enum):\n",
    "    CREATE = \"create\"\n",
    "    GENERATE = \"generate\"\n",
    "    DEADSPACE = \"deadspace\"\n",
    "    FIXED_TIME = \"fixed_time\"\n",
    "    GENERATE_COLLAPSING_WINDOWS = \"generate_collapsing_windows\"\n",
    "    UNION = \"union\"\n",
    "    INTERSECTION = \"intersection\"\n",
    "    DIFFERENCE = \"difference\"\n",
    "    \n",
    "class Segment():\n",
    "    \"\"\"\n",
    "    Distill's segmentation package. Allows the user to segment User Ale log data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_name=\"\", start_end_val=None, num_logs=0, uids=[]):\n",
    "        \"\"\"\n",
    "        Initializes a Segment object.  This object contains metadata for the associated Segment.\n",
    "        :param segment_name: Name associated with the segment, defaults to an empty string\n",
    "        :param start_end_val: A list of tuples (i.e [(start_time, end_time)], where start_time and end_time are Date/Time Objects or integers.  Defaults to a None value.\n",
    "        :param num_logs: Number of logs in the segment.  Defaults to 0.\n",
    "        :param uids: A list of strings representing the associated uids of logs within the segment. Defaults to an empty list.\n",
    "        \"\"\"\n",
    "\n",
    "        self.segment_name = segment_name # string\n",
    "        self.start_end_val = start_end_val # a list of tuples (i.e [(start_time, end_time)], where start_time and end_time are Date/Time Objects or integers.  Defaults to a None value.\n",
    "        self.num_logs = num_logs # int\n",
    "        self.uids = uids # list of uuids\n",
    "        self.generate_field_name = None # string\n",
    "        self.generate_matched_values = None # list of values\n",
    "        self.segment_type = None # Enumerated type\n",
    "\n",
    "def string_to_float_ascii_list(s):\n",
    "    ascii_list = []\n",
    "    for char in s:\n",
    "        ascii_list.append(ord(char))\n",
    "    return ascii_list\n",
    "\n",
    "def ascii_list_to_string(ascii_list):\n",
    "    print(ascii_list)\n",
    "    s = \"\"\n",
    "    for ascii_value in ascii_list:\n",
    "        if ascii_value >= 0 and ascii_value <= 127:\n",
    "            s += chr(ascii_value)\n",
    "    return s\n",
    "\n",
    "def uuid_to_float_list(id):\n",
    "    lst = [float(id.time), float(id.clock_seq), float(id.node)]\n",
    "    return lst\n",
    "\n",
    "def seg_to_array(segment):\n",
    "    name_lst = string_to_float_ascii_list(segment.segment_name)\n",
    "    start_end_tup = segment.start_end_val[0]\n",
    "    segment_array = np.array([[float(start_end_tup[0].timestamp()), float(start_end_tup[1].timestamp()), \n",
    "                               float(segment.num_logs)] + name_lst])\n",
    "    return segment_array\n",
    "\n",
    "def array_to_seg(arr):\n",
    "    start, end, num_logs = arr[:3]\n",
    "    name = ascii_list_to_string(arr[3:])\n",
    "#     start_end_val = [(datetime.fromtimestamp(start), datetime.fromtimestamp(end))]\n",
    "    start_end_val = [(0, 0)]\n",
    "    uids = []\n",
    "    print(\"DECODED: \", \"name: \", name, \"start_end_val: \", start_end_val, \"num_logs: \", num_logs, \"uids: \", uids)\n",
    "    seg = Segment(name, start_end_val, num_logs, uids)\n",
    "    return seg\n",
    "    \n",
    "class SegmentAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SegmentAutoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = torch.nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def train(self, segments, lr=0.1, batch_size=32, num_epochs=100):\n",
    "        # Convert segments to arrays\n",
    "        segment_arrays = [seg_to_array(seg) for seg in segments]\n",
    "        segment_arrays = np.concatenate(segment_arrays, axis=0)\n",
    "\n",
    "        # Create PyTorch DataLoader\n",
    "        dataset = torch.utils.data.TensorDataset(torch.Tensor(segment_arrays))\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Define optimizer and loss function\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        # Train loop\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                inputs = batch[0]\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, inputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "#             epoch_loss = running_loss / len(segment_arrays)\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            if (epoch+1)%1000 == 0:\n",
    "                print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "            # Call the train() method of the parent class to update the parameters\n",
    "            super(SegmentAutoencoder, self).train()\n",
    "\n",
    "    def encode(self, segment):\n",
    "        # Make segment_name into some function of its ascii numeric values - or word2vec\n",
    "        # Combine start_end_val datetime tuple element floats as a single float\n",
    "        # Keep num_logs the same value\n",
    "        # Convert uids list into floats that combine into a single float\n",
    "        segment_array = seg_to_array(segment)\n",
    "#         print(\"segment_array: \", segment_array)\n",
    "#         segment_array = np.array([[len(segment.uids), len(segment.segment_name)]])\n",
    "        with torch.no_grad():\n",
    "            encoded = self.encoder(torch.Tensor(segment_array))\n",
    "        return encoded.squeeze().tolist()\n",
    "    \n",
    "    def decode(self, encoded):\n",
    "        # Convert all of the floats from the encoded value(s) back\n",
    "        encoded = np.array(encoded)\n",
    "        encoded = encoded.reshape((1, -1))  # Reshape to (1, latent_dim) - dimensionality of the latent space\n",
    "        with torch.no_grad():\n",
    "            decoded = self.decoder(torch.Tensor(encoded))\n",
    "        decoded = [i for i in decoded.squeeze().tolist()]\n",
    "        seg = array_to_seg(decoded)\n",
    "        return seg\n",
    "\n",
    "# Create some Segment objects\n",
    "segments = []\n",
    "seg1 = distill.Segment(segment_name=\"Segment 1\", start_end_val=[(datetime.now(), datetime.now())], num_logs=1, uids=[\"uid1\", \"uid2\", \"uid3\", \"uid4\", \"uid5\"])\n",
    "seg2 = distill.Segment(\"Segment 2\", [(datetime.now(), datetime.now())], 2, [\"uid6\", \"uid7\", \"uid8\"])\n",
    "seg3 = distill.Segment(\"Segment 3\", [(datetime.now(), datetime.now())], 3, [\"uid9\", \"uid10\", \"uid11\",\"uid12\"])\n",
    "seg4 = distill.Segment(\"Segment 4\", [(datetime.now(), datetime.now())], 4, [\"uid13\", \"uid14\"])\n",
    "seg5 = distill.Segment(\"Segment 5\", [(datetime.now(), datetime.now())], 5, [\"uid15\", \"uid16\"])\n",
    "seg6 = distill.Segment(\"Segment 6\", [(datetime.now(), datetime.now())], 6, [\"uid17\", \"uid18\", \"uid19\"])\n",
    "segments.append(seg1)\n",
    "segments.append(seg2)\n",
    "segments.append(seg3)\n",
    "segments.append(seg4)\n",
    "segments.append(seg5)\n",
    "segments.append(seg6)\n",
    "\n",
    "# Initialize the autoencoder\n",
    "input_size = 12\n",
    "hidden_size = 1 #doubles as the encoding dimension\n",
    "autoencoder = SegmentAutoencoder(input_size, hidden_size)\n",
    "\n",
    "# Train the autoencoder on the Segment objects\n",
    "autoencoder.train(segments, num_epochs=10000)\n",
    "\n",
    "# Convert a Segment object to a float using the trained autoencoder\n",
    "seg7 = Segment(\"Segment 7\", [(datetime.now(), datetime.now())], 7, [\"uid20\", \"uid21\", \"uid22\"])\n",
    "encoded = autoencoder.encode(seg7)\n",
    "print(\"Encoded Segment 7:\", encoded)\n",
    "decoded = autoencoder.decode(encoded)\n",
    "print(\"Decoded Segment 7:\", decoded)\n",
    "print(\"Decoded Segment 7:\", \"segment_name: \", decoded.segment_name, \"start_end_val: \", decoded.start_end_val, \n",
    "      \"num_logs: \", decoded.num_logs,\"uids: \", decoded.uids, \"generate_field_name: \", decoded.generate_field_name, \n",
    "      \"generate_matched_values: \", decoded.generate_matched_values, \"segment_type: \", decoded.segment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([-0.1290, -0.0477])\n",
      "y:  tensor([-0.0477, -0.2104])\n",
      "Epoch 100/2000, Loss: 0.06411346793174744\n",
      "Epoch 200/2000, Loss: 0.0007003856007941067\n",
      "Epoch 300/2000, Loss: 0.00041232482180930674\n",
      "Epoch 400/2000, Loss: 0.00021235494932625443\n",
      "Epoch 500/2000, Loss: 9.556979057379067e-05\n",
      "Epoch 600/2000, Loss: 3.751950498553924e-05\n",
      "Epoch 700/2000, Loss: 1.2841665011364967e-05\n",
      "Epoch 800/2000, Loss: 3.833949449472129e-06\n",
      "Epoch 900/2000, Loss: 9.992822924687061e-07\n",
      "Epoch 1000/2000, Loss: 2.2732254478796676e-07\n",
      "Epoch 1100/2000, Loss: 4.505579553892858e-08\n",
      "Epoch 1200/2000, Loss: 7.750125874395053e-09\n",
      "Epoch 1300/2000, Loss: 1.1520140397180967e-09\n",
      "Epoch 1400/2000, Loss: 1.472966193460934e-10\n",
      "Epoch 1500/2000, Loss: 1.63229429972489e-11\n",
      "Epoch 1600/2000, Loss: 1.595168441781425e-12\n",
      "Epoch 1700/2000, Loss: 4.2366110619695974e-13\n",
      "Epoch 1800/2000, Loss: 1.9473311851925246e-13\n",
      "Epoch 1900/2000, Loss: 9.237055564881302e-14\n",
      "Epoch 2000/2000, Loss: 4.440892098500626e-14\n",
      "Nodes: [-0.12904709577560425, -0.047683149576187134, -0.21041104197502136]\n",
      "Output: tensor([[-0.0583]], grad_fn=<AddmmBackward0>)\n",
      "Decoded Segment: segment_name:   start_end_val:  [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)] num_logs:  6 uids:  [] generate_field_name:  None generate_matched_values:  None segment_type:  None\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a sample graph with the most basic data\n",
    "\n",
    "# Sort the list of objects according to each object's creation time\n",
    "segments.sort(key=lambda x: x.start_end_val[0], reverse=True)\n",
    "# For each object, append its numeric encoding to the list of encoded_objects\n",
    "encoded_segs = []\n",
    "for s in segments:\n",
    "    e = autoencoder.encode(s)\n",
    "    encoded_segs.append(e) #Accessing first element for float value, try just \"e\", too\n",
    "# Define a sample graph with our embedded objects\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(encoded_segs[0],encoded_segs[1]), (encoded_segs[1],encoded_segs[2]), (encoded_segs[1],encoded_segs[3]), \n",
    "                  (encoded_segs[2],encoded_segs[3]), (encoded_segs[3],encoded_segs[0])])\n",
    "\n",
    "# Train the model on a list of graphs (just one for now, becuase generating so many is annoying)\n",
    "graphs = [G]\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "num_epochs = 2000\n",
    "model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "# Test the model by predicting the next most probable node (after the most recently created obj) in the graph\n",
    "input_node = torch.tensor([encoded_segs[3]], dtype=torch.float32)\n",
    "hidden = model.init_hidden()\n",
    "output, hidden = model(input_node, hidden)\n",
    "print(f'Nodes: {G.nodes()}')\n",
    "print(f'Output: {output}')\n",
    "decoded = autoencoder.decode(output[0].item())\n",
    "print(\"Decoded Segment:\", \"segment_name: \", decoded.segment_name, \"start_end_val: \", decoded.start_end_val, \n",
    "      \"num_logs: \", decoded.num_logs,\"uids: \", decoded.uids, \"generate_field_name: \", decoded.generate_field_name, \n",
    "      \"generate_matched_values: \", decoded.generate_matched_values, \"segment_type: \", decoded.segment_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next objective:** Find a way to translate the segment objects into autoencoded embeddings for training before translating them back into the predicted output segment we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee3d06e2f47c379c84ddc2f8584ef1b36487d010a572cd3eb9e58b6881766743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
