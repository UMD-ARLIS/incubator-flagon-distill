{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Prediction Model\n",
    "In this notebook, we run through an experiment using UserALE data generated within an instantiation of Superset.  This data reflects four simulated user sessions in which the user performs three tasks within the Video Game Sales example dashboard:\n",
    "\n",
    "1. Filter the games for Wii, Racing, and Nintendo.\n",
    "2. Find Mario Kart in the list of games.\n",
    "3. Determine the difference in global sales between the 3DS game Nintendogs + cats and Wii Sports.\n",
    "\n",
    "The data of these four sessions is captured in a json file within the data folder entitled `task_example.json`.  In this experiment, we will:\n",
    "\n",
    "* Experiment with the efficacy of several predictive models to determine which is the best for our objective\n",
    "* Attempt to plug the `DiGraph` objects resulting from `task_example.json` into the model we choose\n",
    "* Tune the resulting model to minimize loss and maximize prediction accuracy\n",
    "\n",
    "**Note: The data utilized in this example was not data collected in any user study.  Rather this data is simulated through developer interactions with the Superset dashboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy Code:\n",
    "\n",
    "Generates the graph lists and structures that we'll eventually use for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import datetime\n",
    "import distill\n",
    "import json\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "def setup(file, date_type):\n",
    "    with open(file) as json_file:\n",
    "        raw_data = json.load(json_file)\n",
    "\n",
    "    data = {}\n",
    "    for log in raw_data:\n",
    "        data[distill.getUUID(log)] = log\n",
    "        \n",
    "    # Convert clientTime to specified type\n",
    "    for uid in data:\n",
    "        log = data[uid]\n",
    "        client_time = log['clientTime']\n",
    "        if date_type == \"integer\":\n",
    "            log['clientTime'] = distill.epoch_to_datetime(client_time)\n",
    "        elif date_type == \"datetime\":\n",
    "            log['clientTime'] = pd.to_datetime(client_time, unit='ms', origin='unix')\n",
    "\n",
    "    # Sort\n",
    "    sorted_data = sorted(data.items(), key=lambda kv: kv[1]['clientTime'])\n",
    "    sorted_dict = dict(sorted_data)\n",
    "\n",
    "    return (sorted_data, sorted_dict)\n",
    "\n",
    "def draw_digraph(segments):\n",
    "    nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "    edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "    \n",
    "    # Set coloring of graph based on element in Superset dashboard\n",
    "    color_map = []\n",
    "    for segment in segments:\n",
    "        if re.match(\"Game_Filter\\S*\", segment.segment_name):\n",
    "            color_map.append('green')\n",
    "        else:\n",
    "            color_map.append('blue')\n",
    "    \n",
    "    graph = distill.createDiGraph(nodes, edges)\n",
    "    nx.draw(graph, node_color=color_map)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_many_session = setup(\"./data/task_example.json\", \"datetime\")\n",
    "sorted_dict = data_many_session[1]\n",
    "\n",
    "# Create segments based on sessionID\n",
    "segments = distill.Segments()\n",
    "session_ids = sorted(distill.find_meta_values('sessionID', sorted_dict), key=lambda sessionID: sessionID)\n",
    "for session_id in session_ids:\n",
    "    segments.append_segments(distill.generate_collapsing_window_segments(sorted_dict, 'sessionID', [session_id], session_id))\n",
    "    \n",
    "# Improve readability of Segment names\n",
    "for index in range(len(segments)):\n",
    "    segments[index].segment_name = \"Session\" + str(index)\n",
    "    \n",
    "    \n",
    "segment_names = [segment.segment_name for segment in segments]\n",
    "start_end_vals = [segment.start_end_val for segment in segments]\n",
    "segment_map = distill.write_segment(sorted_dict, segment_names, start_end_vals)\n",
    "\n",
    "session_0_segments = distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_1_segments = distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_2_segments = distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "session_3_segments = distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div.filter-container css-ffe7is'], \"Game_Filter\")\n",
    "\n",
    "session_0_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session0'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_1_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session1'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_2_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session2'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "session_3_segments.append_segments(distill.generate_collapsing_window_segments(segment_map['Session3'], 'path', ['div#chart-id-110.superset-chart-table'], \"Games\"))\n",
    "\n",
    "segments.append_segments(session_0_segments)\n",
    "segments.append_segments(session_1_segments)\n",
    "segments.append_segments(session_2_segments)\n",
    "segments.append_segments(session_3_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example user-activity graph:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G0 = draw_digraph(session_0_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source code found at https://towardsdatascience.com/build-a-super-simple-gan-in-pytorch-54ba349920e4\n",
    "\n",
    "Very basic task: Training a GAN to generate positive integers using vectors of their binary encodings (Ex: 56 is 0111000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def create_binary_list_from_int(number: int) -> List[int]:\n",
    "    if number < 0 or type(number) is not int:\n",
    "        raise ValueError(\"Only Positive integers are allowed\")\n",
    "\n",
    "    return [int(x) for x in list(bin(number))[2:]]\n",
    "\n",
    "def generate_even_data(max_int: int, batch_size: int=16) -> Tuple[List[int], List[List[int]]]:\n",
    "    # Get the number of binary places needed to represent the maximum number\n",
    "    max_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Sample batch_size number of integers in range 0-max_int\n",
    "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
    "\n",
    "    # create a list of labels all ones because all numbers are even\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    # Generate a list of binary numbers for training.\n",
    "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
    "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
    "\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Generator:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense = nn.Linear(int(input_length), 1);\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(max_int: int = 128, batch_size: int = 16, training_steps: int = 201):\n",
    "    input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    # Models\n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    # Optimizers\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "\n",
    "    # loss\n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        # zero the gradients on each iteration\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        # Create noisy input for generator\n",
    "        # Need float type instead of int\n",
    "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "        \n",
    "        # Generate examples of even real data\n",
    "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
    "        true_labels = torch.tensor(true_labels).unsqueeze(1).float()\n",
    "        true_data = torch.tensor(true_data).float()\n",
    "\n",
    "        # Train the generator\n",
    "        # We invert the labels here and don't train the discriminator because we want the generator\n",
    "        # to make things the discriminator classifies as true.\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        # Print generator's loss at every 50th step\n",
    "        if (i % 50)==0 :\n",
    "          print(\"STEP \", str(i))\n",
    "          print(generator_loss)\n",
    "\n",
    "        # Train the discriminator on the true/generated data\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        # add .detach() here think about this\n",
    "        z = torch.zeros(batch_size).unsqueeze(1)\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(generator_discriminator_out, z)\n",
    "        discriminator_loss = (true_discriminator_loss + generator_discriminator_loss) / 2\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP  0\n",
      "tensor(1.0166, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  50\n",
      "tensor(0.9037, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  100\n",
      "tensor(0.8029, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  150\n",
      "tensor(0.7511, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "STEP  200\n",
      "tensor(0.7232, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So essentially what we'd do for the graphs is, instead of feeding integers, we would feed session data. Feature vectors would represent [div_1, div_2, ..., div_n] with each element denoting whether or not an element was clicked at that segment of the session (vertex of the graph). Only problem is, human-made session data is not so easily generated as it is with random numbers in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary so far:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I've read:\n",
    "* (GAN theory) https://www.frontiersin.org/articles/10.3389/fdata.2019.00003/full\n",
    "* (undirected graphs GAN with tensorflow) https://github.com/hwwang55/GraphGAN (further documentation: https://arxiv.org/pdf/1711.08267.pdf)\n",
    "* (directed graphs GAN with pytorch) https://github.com/THUDM/GraphSGAN (further documentation: https://arxiv.org/pdf/1809.00130.pdf)\n",
    "\n",
    "As a result, I have a good idea of the theory and am currently working out how to reverse-engineer the third link which looks most promising. All my notes on this are currently in a word doc.\n",
    "\n",
    "**Current Problems:**\n",
    "* A GAN typically requires 50,000-100,000 images/graphs to train on, and we only have 4 graphs in the example\n",
    "* Having a hard time percieving the third link's input data and how to translate ours to fit its format\n",
    "\n",
    "**Questions:**\n",
    "* How accurate would we want our GAN generator to be? (loss-wise)\n",
    "* Realistically, how many training sessions can we get beyond the 4 that exist in the example json?\n",
    "* Might be possible to generate the data in a way that doesn't require ML. Maybe through bots or something? Do we want the session data to strictly reflect the behavior of human users?\n",
    "* What are we looking for in our model? For it to know a typical series of clicks that the average user might generate? In this case, should we consider an ngram-style neural network we could use as a sequence generator (replacing words with segments), instead?\n",
    "\n",
    "**Input:**\n",
    "* Stop working on GANs. Too much data is required for training.\n",
    "* Start working on ngram NN\n",
    "* Essentially: Predict the next graph in a series of graphs by averaging the past ones\n",
    "* Purpose: Predicting future user activity based on their past activity. But for now, we will be using the activity of multiple users to predict future activity of the average user\n",
    "* Aside: If it so happens that our model does not train well, there’s a chance it’s because the data we’re using is flawed. Inform them of this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram NN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the structure of the segments for good measure (scrap once understood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UIDS:  ['session_16527363465571652736427217rawmouseover', 'session_16527363465571652736427318rawscroll', 'session_16527363465571652736428683rawmouseover', 'session_16527363465571652736428699rawmouseover', 'session_16527363465571652736428763rawmouseover', 'session_16527363465571652736428909rawwheel', 'session_16527363465571652736428921rawscroll', 'session_16527363465571652736429603rawmouseover', 'session_16527363465571652736429779rawmouseover', 'session_16527363465571652736429835rawmouseover', 'session_16527363465571652736430013rawmouseover', 'session_16527363465571652736430117rawmouseover', 'session_16527363465571652736433401rawmouseover', 'session_16527363465571652736433433rawmouseover', 'session_16527363465571652736433465rawmouseover', 'session_16527363465571652736434235rawmouseover', 'session_16527363465571652736434331rawmouseover', 'session_16527363465571652736436417rawmouseover', 'session_16527363465571652736436433rawmouseover']\n",
      "NAME:  Games5\n",
      "FIELD NAME:  path\n",
      "LENGTH:  25\n"
     ]
    }
   ],
   "source": [
    "segments = session_0_segments\n",
    "nodes = sorted(segments.get_segment_list(), key=lambda segment: segment.start_end_val[0])\n",
    "edges = distill.pairwiseSeq(segments.get_segment_list())\n",
    "print( \"UIDS: \", nodes[24].get_segment_uids() )\n",
    "print( \"NAME: \", nodes[24].get_segment_name() )\n",
    "print( \"FIELD NAME: \", nodes[24].get_generate_field_name() )\n",
    "print( \"LENGTH: \", len(nodes) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ngram was scrapped in favor of GNNs until further notice.** See https://arxiv.org/pdf/2202.06081.pdf for inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Research / Fooling Around:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read through the following sources/tutorials:\n",
    "\n",
    "- General GNN overview information: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- More GNN overview information: https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275\n",
    "- Link Prediction with planetary Cora dataset: https://www.datacamp.com/tutorial/comprehensive-introduction-graph-neural-networks-gnns-tutorial\n",
    "- Graph classification with Heterogeneous data: https://blog.dataiku.com/graph-neural-networks-merging-deep-learning-with-graphs\n",
    "\n",
    "Ultimately decided on building our prototype from the following tutorial due to the fact that we want a model for Link Prediction of homogeneous graphs with complex node structure (Segment objects): https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two\n",
    "Even though the data in this link's graph is heterogeneous, the concept application is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Began implementing the Cora planetary dataset code before realizing their data is very heterogeneous and graph structure seems a little more dissimilar to ours. May revisit if it otherwise becomes especially interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import os\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# os.environ['PYTHONWARNINGS'] = \"ignore\"\n",
    "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('======================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# data = dataset[0]  # Get the first graph object.\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation of the more-relevant heterogeneous graph dataiku tutorial instead:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The \"mean aggregator\" as mentioned in https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two may be especially useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Predict the rating that a given user is likely to give to the most recent movies. This prediction would then be used to suggest the most relevant movie.\n",
    "\n",
    "Modeling: The problem can be modeled as a graph with two types of nodes: one representing users and the other movies. A user node is linked to the movie node if the user has rated the movie and is labeled with the rating.\n",
    "\n",
    "Task: Under this modeling, the problem becomes a link prediction task where the goal is to predict the label (rating) of a link between a user node and a movie node.\n",
    "\n",
    "Their Original code: https://github.com/linafaik08/graph_neural_networks/blob/main/2_link_prediction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My concerns:\n",
    "- This code depends on user-movie relationships (how do we strip away the user aspect?)\n",
    "- This code uses a KNN approach (maps movies' feature vectors into a vector space and suggests links between nodes in those K classes from there)\n",
    "- Link prediction creates a matrix of all possible edges that could exist between all existent nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our repurposed tutorial code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorials proved too far from the problem to offer anything beyond niche understandings of the link prediction process, so I scraped them. May return back if they prove helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Scratch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Not shown) I tried one version that was very specific to our data, but it started to become a mess with how many transitory methods I had to use to translate the graphs from one state to another and so on. \n",
    "\n",
    "Instead, I eventually decided to go very simple and build from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([1., 2., 3.])\n",
      "y:  tensor([2., 3., 4.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 20.703353881835938\n",
      "Epoch 200/2000, Loss: 5.706105709075928\n",
      "Epoch 300/2000, Loss: 0.7145375609397888\n",
      "Epoch 400/2000, Loss: 0.26223835349082947\n",
      "Epoch 500/2000, Loss: 0.2225249707698822\n",
      "Epoch 600/2000, Loss: 0.19210894405841827\n",
      "Epoch 700/2000, Loss: 0.16598697006702423\n",
      "Epoch 800/2000, Loss: 0.14396114647388458\n",
      "Epoch 900/2000, Loss: 0.12547741830348969\n",
      "Epoch 1000/2000, Loss: 0.1095893606543541\n",
      "Epoch 1100/2000, Loss: 0.09538678079843521\n",
      "Epoch 1200/2000, Loss: 0.08229909837245941\n",
      "Epoch 1300/2000, Loss: 0.07006819546222687\n",
      "Epoch 1400/2000, Loss: 0.05857817828655243\n",
      "Epoch 1500/2000, Loss: 0.04765802249312401\n",
      "Epoch 1600/2000, Loss: 0.03698821738362312\n",
      "Epoch 1700/2000, Loss: 0.026251614093780518\n",
      "Epoch 1800/2000, Loss: 0.015446283854544163\n",
      "Epoch 1900/2000, Loss: 0.005444975569844246\n",
      "Epoch 2000/2000, Loss: 0.0003546250518411398\n",
      "Nodes: [1, 2, 3, 4]\n",
      "Output: tensor([[2.5613]], grad_fn=<AddmmBackward0>)\n",
      "Predicted next node: 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model class\n",
    "class GraphLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(graphs):\n",
    "    X, y = [], []\n",
    "    for graph in graphs:\n",
    "        nodes = list(graph.nodes())\n",
    "        for i in range(len(nodes) - 1):\n",
    "            X.append(np.array(nodes[i]))\n",
    "            y.append(np.array(nodes[i+1]))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the main function to train the model\n",
    "def train_model(graphs, input_size, hidden_size, output_size, num_epochs):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(graphs)\n",
    "    print(\"X: \", X)\n",
    "    print(\"y: \", y)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = GraphLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = model.init_hidden()\n",
    "        loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(X[i], hidden)\n",
    "            loss += criterion(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if ((epoch+1)%100)==0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Test the model on a sample graph with the most basic data\n",
    "if __name__ == '__main__':\n",
    "    # Define a sample graph\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(1,2), (2,3), (2,4), (3,4), (4,1)])\n",
    "\n",
    "    # Train the model on a list of graphs\n",
    "    graphs = [G]\n",
    "    input_size = 1\n",
    "    hidden_size = 10\n",
    "    output_size = 1\n",
    "    num_epochs = 2000\n",
    "    model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "    # Test the model by predicting the next most probable node (after 4) in the graph\n",
    "    input_node = torch.tensor([4], dtype=torch.float32)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_node, hidden)\n",
    "    predicted_node = round( max(output.detach().numpy()[0]) )\n",
    "    print(f'Nodes: {G.nodes()}')\n",
    "    print(f'Output: {output}')\n",
    "    print(f'Predicted next node: {predicted_node}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary Goal Accomplished:** Prove LSTM sequential prediction works with simple float types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try the same LSTM on more complicated arbitrary Object types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll build an autoencoder that embeds the arbitrary Object types into numeric floats we can plug into an LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:  tensor([[2.0000e-01, 1.7905e+17, 7.1040e+03, 2.6593e+13, 1.6801e+09],\n",
      "        [3.0000e-01, 1.1461e+18, 1.2583e+04, 1.3372e+14, 1.6801e+09],\n",
      "        [4.0000e-01, 9.0325e+17, 9.3860e+03, 1.6849e+14, 1.6801e+09],\n",
      "        [1.0000e-02, 8.1385e+17, 7.2900e+03, 2.1736e+14, 1.6801e+09]])\n",
      "TEST OBJECT:  name:  apple color:  red weight:  0.2 id:  8ae62bbd-1975-427c-9bc0-182f90ca37fb creation time:  2023-03-29 18:16:20.208456\n",
      "ENCODED:  [4.552038e+15]\n",
      "ARRAY:  [1. 0. 1. 0. 0.]\n",
      "DECODED:  name:   color:   weight:  1.0 id:  00000000-0000-0000-0001-000000000000 creation time:  1969-12-31 19:00:00\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Obj:\n",
    "    # constructor function    \n",
    "    def __init__(self, name, color, weight):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        self.weight = weight\n",
    "        self.id = uuid.uuid4()\n",
    "        self.creation_time = datetime.now()\n",
    "\n",
    "    def to_string(self):\n",
    "        # return f\"Object is named \\\"{self.name}\\\", has a {self.color} color, and weighs {self.weight}lbs with a UUID of {self.id} created at {self.creation_time}.\"\n",
    "        return f\"\\\"{self.name}\\\" created at {self.creation_time}.\"\n",
    "    \n",
    "    def to_array(self):\n",
    "        # First problem was it was attempting to convert strings to floats\n",
    "        # Second problem is there is no 5th elem\n",
    "        return [float(self.weight), float(self.id.time), float(self.id.clock_seq), \n",
    "                float(self.id.node), float(self.creation_time.timestamp())]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_array(arr):\n",
    "        print(\"ARRAY: \", arr)\n",
    "        weight = arr[0]\n",
    "        id_time = int(arr[1])\n",
    "        id_clock_seq = int(arr[2])\n",
    "        id_node = int(arr[3])\n",
    "        timestamp = int(arr[4].item())\n",
    "        time_low = id_time & 0xFFFFFFFF\n",
    "        time_mid = (id_time >> 32) & 0xFFFF\n",
    "        time_hi_version = (id_time >> 48) & 0x0FFF\n",
    "        clock_seq_hi_variant = (id_clock_seq >> 8) & 0xFF\n",
    "        clock_seq_low = id_clock_seq & 0xFF\n",
    "        node = id_node.to_bytes(6, byteorder='big')\n",
    "        fields = (time_low, time_mid, time_hi_version, clock_seq_hi_variant, clock_seq_low, int.from_bytes(node, byteorder='big'))\n",
    "        creation_time = datetime.fromtimestamp(timestamp)\n",
    "        obj = Obj(\"\", \"\", weight) #Empty strings are used in place of None types\n",
    "        obj.id = uuid.UUID(fields=fields)\n",
    "        obj.creation_time = creation_time\n",
    "        return obj\n",
    "\n",
    "class ObjAutoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(5, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 2 * encoding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * encoding_dim, 5),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def train(self, objs, epochs=100, batch_size=32):\n",
    "        x_train = torch.tensor([obj.to_array() for obj in objs], dtype=torch.float32)\n",
    "        print(\"TRAINING DATA: \", x_train)\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, x_train.shape[0], batch_size):\n",
    "                batch = x_train[i:i+batch_size]\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(batch)\n",
    "                loss = loss_fn(outputs, batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def encode(self, obj):\n",
    "        x = torch.tensor(obj.to_array(), dtype=torch.float32)\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded.detach().numpy()\n",
    "\n",
    "    def decode(self, encoded):\n",
    "        decoded = self.decoder(torch.tensor(encoded, dtype=torch.float32))\n",
    "        return Obj.from_array(decoded.detach().numpy())\n",
    "\n",
    "# Example usage\n",
    "objs = [Obj(\"apple\", \"red\", 0.2), Obj(\"banana\", \"yellow\", 0.3), Obj(\"orange\", \"orange\", 0.4), Obj(\"thimble\", \"silver\", 0.01)]\n",
    "autoencoder = ObjAutoencoder(encoding_dim=1)\n",
    "autoencoder.train(objs)\n",
    "\n",
    "# Encode an object to a float\n",
    "t = objs[0]\n",
    "print(\"TEST OBJECT: \", \"name: \", t.name, \"color: \", t.color, \"weight: \", t.weight,\"id: \", t.id, \"creation time: \", t.creation_time)\n",
    "encoded = autoencoder.encode(t)\n",
    "print(\"ENCODED: \", encoded)\n",
    "\n",
    "# Decode a float to an object\n",
    "decoded = autoencoder.decode(encoded)\n",
    "print(\"DECODED: \", \"name: \", decoded.name, \"color: \", decoded.color, \"weight: \", decoded.weight,\"id: \", decoded.id, \"creation time: \", decoded.creation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Currently cannot use/predict string types and data integrity is lost in translation. Maybe the integrity is lost because of the autoencoder structure? Or maybe this has to do with not having enough training data? Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plug a graph of embedded floats into our LSTM as training data to generate the next likely Object type in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  tensor([4.5520e+15, 2.9135e+16, 2.2966e+16])\n",
      "y:  tensor([2.9135e+16, 2.2966e+16, 2.0696e+16])\n",
      "Epoch 100/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 200/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 300/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 400/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 500/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 600/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 700/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 800/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 900/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1000/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1100/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1200/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1300/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1400/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1500/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1600/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1700/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1800/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 1900/2000, Loss: 1.8046103418608662e+33\n",
      "Epoch 2000/2000, Loss: 1.8046103418608662e+33\n",
      "Nodes: [4552038000000000.0, 2.9135342e+16, 2.296577e+16, 2.0695787e+16]\n",
      "Output: tensor([[6.1250]], grad_fn=<AddmmBackward0>)\n",
      "ARRAY:  [0.4622929  0.52744275 0.51031667 0.36824307 0.4680188 ]\n",
      "Decoded Output:  name:   color:   weight:  0.4622929 id:  00000000-0000-0000-0000-000000000000 creation time:  1969-12-31 19:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vladimir\\AppData\\Local\\Temp\\ipykernel_8072\\3995729368.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  decoded = self.decoder(torch.tensor(encoded, dtype=torch.float32))\n"
     ]
    }
   ],
   "source": [
    "# Test the model on a sample graph with the most basic data\n",
    "\n",
    "# Sort the list of objects according to each object's creation time\n",
    "objs.sort(key=lambda x: x.creation_time, reverse=True)\n",
    "# For each object, append its numeric encoding to the list of encoded_objects\n",
    "encoded_objs = []\n",
    "for o in objs:\n",
    "    e = autoencoder.encode(o)\n",
    "    encoded_objs.append(e[0]) #Accessing first element for float value, try just \"e\", too\n",
    "# Define a sample graph with our embedded objects\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(encoded_objs[0],encoded_objs[1]), (encoded_objs[1],encoded_objs[2]), (encoded_objs[1],encoded_objs[3]), \n",
    "                  (encoded_objs[2],encoded_objs[3]), (encoded_objs[3],encoded_objs[0])])\n",
    "\n",
    "# Train the model on a list of graphs (just one for now, becuase generating so many is annoying)\n",
    "graphs = [G]\n",
    "input_size = 1\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "num_epochs = 2000\n",
    "model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "# Test the model by predicting the next most probable node (after the most recently created obj) in the graph\n",
    "input_node = torch.tensor([encoded_objs[3]], dtype=torch.float32)\n",
    "hidden = model.init_hidden()\n",
    "output, hidden = model(input_node, hidden)\n",
    "print(f'Nodes: {G.nodes()}')\n",
    "print(f'Output: {output}')\n",
    "decoded = autoencoder.decode(output[0])\n",
    "print('Decoded Output: ', \"name: \", decoded.name, \"color: \", decoded.color, \"weight: \", decoded.weight,\"id: \", decoded.id, \"creation time: \", decoded.creation_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** Our output encodings seem to be leagues away from the embedding values they're trained off. Maybe this has to do with the LSTM structure (before it trained/outputed simple floats, now it trains/outputs large ones)? Or maybe this has to do with not having enough training data? Let's investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try plugging our G0,G1,G2,G3 graph data in (work in progress):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model class\n",
    "class GraphLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        lstm_out, hidden = self.lstm(input.view(1, 1, -1), hidden)\n",
    "        output = self.fc(lstm_out.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size),\n",
    "                torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "# Define a function to preprocess the data\n",
    "def preprocess_data(graphs):\n",
    "    X, y = [], []\n",
    "    for graph in graphs:\n",
    "        nodes = list(graph.nodes())\n",
    "        for i in range(len(nodes) - 1):\n",
    "            X.append(np.array(nodes[i]))\n",
    "            y.append(np.array(nodes[i+1]))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    return X, y\n",
    "\n",
    "# Define the main function to train the model\n",
    "def train_model(graphs, input_size, hidden_size, output_size, num_epochs):\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(graphs)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = GraphLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden = model.init_hidden()\n",
    "        loss = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            model.zero_grad()\n",
    "            output, hidden = model(X[i], hidden)\n",
    "            loss += criterion(output, y[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# # Test the model on a sample graph with the most basic data\n",
    "# if __name__ == '__main__':\n",
    "#     # Define a sample graph\n",
    "#     G = nx.DiGraph()\n",
    "#     G.add_edges_from([(1,2), (2,3), (2,4), (3,4), (4,1)])\n",
    "\n",
    "#     # Train the model on a list of graphs\n",
    "#     graphs = [G]\n",
    "#     input_size = 1\n",
    "#     hidden_size = 10\n",
    "#     output_size = 1\n",
    "#     num_epochs = 100\n",
    "#     model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "#     # Test the model by predicting the next node in the graph\n",
    "#     input_node = torch.tensor([4], dtype=torch.float32)\n",
    "#     hidden = model.init_hidden()\n",
    "#     output, hidden = model(input_node, hidden)\n",
    "#     predicted_node = torch.argmax(output).item()\n",
    "#     print(f'Predicted next node: {predicted_node}')\n",
    "\n",
    "# Test the model on a sample graph with the most basic data\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Train the model on a list of graphs\n",
    "    graphs = [G0, G1, G2]\n",
    "    input_size = 3\n",
    "    hidden_size = 10\n",
    "    output_size = 1\n",
    "    num_epochs = 100\n",
    "    model = train_model(graphs, input_size, hidden_size, output_size, num_epochs)\n",
    "\n",
    "    # Test the model by predicting the next node in the graph\n",
    "    \n",
    "    # Problem: G3 needs to be turned into an embedding of type float32\n",
    "    input_node = torch.tensor([G3], dtype=torch.float32)\n",
    "    hidden = model.init_hidden()\n",
    "    output, hidden = model(input_node, hidden)\n",
    "    predicted_node = max(output.tolist())\n",
    "#     print(f'input node: {input_node}')\n",
    "    print(f'Nodes: {G.nodes()}')\n",
    "    print(f'Output: {output.tolist()}')\n",
    "    print(f'Predicted next node: {predicted_node}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next objective:** Find a way to translate the segment objects into autoencoded embeddings for training before translating them back into the predicted output segment we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee3d06e2f47c379c84ddc2f8584ef1b36487d010a572cd3eb9e58b6881766743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
